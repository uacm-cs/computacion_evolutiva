{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuroevolución\n",
    "- ### La neuroevolución es una técnica de inteligencia artificial que combina redes neuronales con algoritmos evolutivos.\n",
    "- ### Optimiza automáticamente la estructura y parámetros de una red.\n",
    "\n",
    "## Inspiración biológica:\n",
    "\n",
    "- ### Se basa en la evolución natural (selección, mutación y recombinación).\n",
    "\n",
    "- ### Las redes neuronales \"evolucionan\" para adaptarse a una tarea.\n",
    "\n",
    "## Tipos principales:\n",
    "\n",
    "- ### Evolución de pesos: Optimiza los parámetros: pesos y sesgos ($bias$) de una red fija.\n",
    "\n",
    "- ### Evolución de topologías: Modifica la arquitectura de la red (Por ejemplo, el método NEAT).\n",
    "\n",
    "## Ventajas:\n",
    "\n",
    "- ### No requiere del cálculo de gradientes (útil para problemas no diferenciables).\n",
    "\n",
    "- ### Explora múltiples soluciones en paralelo.\n",
    "\n",
    "- ### Puede descubrir arquitecturas novedosas.\n",
    "\n",
    "## Aplicaciones:\n",
    "\n",
    "- ### Control de robots.\n",
    "\n",
    "- ### Juegos (Por ejemplo, videojuegos clásicos).\n",
    "\n",
    "- ### Optimización de hiperparámetros.\n",
    "\n",
    "## Algoritmos populares:\n",
    "\n",
    "- ### NEAT (NeuroEvolution of Augmenting Topologies).\n",
    "\n",
    "- ### CMA-ES (Covariance Matrix Adaptation Evolution Strategy).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación de Textos por medio de Neuroevolución"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/fig-diagrama-clasificador.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenar al clasificador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificador: Red Neuronal Multicapa\n",
    "- #### Define una red con una arquitectura que consta de:\n",
    "    - #### 2 datos de entrada ($x_1$, $x_2$)\n",
    "    - #### capa 1 (4 neuronas)\n",
    "    - #### capa 2 (3 neuronas)\n",
    "    - #### capa 3 (2 neuronas): 2 datos de salida ($y_1$, $y_2$)\n",
    "\n",
    "<center>\n",
    "<img src=\"figs/fig-red_neuronal.png\" width=\"800\" style=\"background-color:white;\">\n",
    "</center>\n",
    "\n",
    "\n",
    "\n",
    "- #### Número de parámetros de la red:\n",
    "    - #### Pesos en la capa 1: $w_{ij}^{(1)}$ = 8 (2 entradas x 4 neuronas) y   4 sesgos ($bias$) (1 de cada neurona)\n",
    "    - #### Pesos en la capa 2: $w_{ij}^{(2)}$ = 12 (4 entradas [4 neuronas de la capa 1] x 3 neuronas) y  3 sesgos ($bias$) (1 de cada neurona)\n",
    "    - #### Pesos en la capa 3: $w_{ij}^{(3)}$ = 6 (3 entradas [3 neuronas de la capa 2] x 2 neuronas) y  2 sesgos ($bias$) (1 de cada neurona)\n",
    "    - #### Total de parámetros: 35 (pesos y $bias$)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Cargar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de ejemplos de entrenamiento\n",
      "klass\n",
      "neutral     1485\n",
      "positive     968\n",
      "negative     689\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_json(\"./data/dataset_polaridad_es_train.json\", lines=True)\n",
    "#conteo de clases\n",
    "print(\"Total de ejemplos de entrenamiento\")\n",
    "print(dataset.klass.value_counts())\n",
    "# Extracción de los textos en arreglos de numpy\n",
    "X = dataset['text'].to_numpy()\n",
    "# Extracción de las etiquetas o clases de entrenamiento\n",
    "Y = dataset['klass'].to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Codificar las categorías (clases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases:\n",
      "['negative' 'neutral' 'positive']\n",
      "Clases codificadas:\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "import torch\n",
    "from torch import nn\n",
    "# Normalizar las etiquetas a una codificación ordinal para entrada del clasificador\n",
    "Y_encoded= le.fit_transform(Y)\n",
    "print(\"Clases:\")\n",
    "print(le.classes_)\n",
    "print(\"Clases codificadas:\")\n",
    "print(le.transform(le.classes_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Preparar los conjuntos de datos  (datasets) para entrenamiento y para probar el rendimiento del clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir el conjunto de datos en conjunto de entrenamiento (80%) y conjunto de pruebas (20%)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, Y_train, Y_val =  train_test_split(X, Y_encoded, test_size=0.2, stratify=Y_encoded, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Crear Matriz Documento-Término"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulario:  5660\n",
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [2]\n",
      " [0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/opt/miniconda3/envs/CE/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk import word_tokenize\n",
    "import numpy as np\n",
    "\n",
    "_STOPWORDS = stopwords.words(\"spanish\")  # agregar más palabras a esta lista si es necesario\n",
    "\n",
    "# Normalización del texto\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "PUNCTUACTION = \";:,.\\\\-\\\"'/\"\n",
    "SYMBOLS = \"()[]¿?¡!{}~<>|\"\n",
    "NUMBERS= \"0123456789\"\n",
    "SKIP_SYMBOLS = set(PUNCTUACTION + SYMBOLS)\n",
    "SKIP_SYMBOLS_AND_SPACES = set(PUNCTUACTION + SYMBOLS + '\\t\\n\\r ')\n",
    "\n",
    "def normaliza_texto(input_str,\n",
    "                    punct=False,\n",
    "                    accents=False,\n",
    "                    num=False,\n",
    "                    max_dup=2):\n",
    "    \"\"\"\n",
    "        punct=False (elimina la puntuación, True deja intacta la puntuación)\n",
    "        accents=False (elimina los acentos, True deja intactos los acentos)\n",
    "        num= False (elimina los números, True deja intactos los acentos)\n",
    "        max_dup=2 (número máximo de símbolos duplicados de forma consecutiva, rrrrr => rr)\n",
    "    \"\"\"\n",
    "    \n",
    "    nfkd_f = unicodedata.normalize('NFKD', input_str)\n",
    "    n_str = []\n",
    "    c_prev = ''\n",
    "    cc_prev = 0\n",
    "    for c in nfkd_f:\n",
    "        if not num:\n",
    "            if c in NUMBERS:\n",
    "                continue\n",
    "        if not punct:\n",
    "            if c in SKIP_SYMBOLS:\n",
    "                continue\n",
    "        if not accents and unicodedata.combining(c):\n",
    "            continue\n",
    "        if c_prev == c:\n",
    "            cc_prev += 1\n",
    "            if cc_prev >= max_dup:\n",
    "                continue\n",
    "        else:\n",
    "            cc_prev = 0\n",
    "        n_str.append(c)\n",
    "        c_prev = c\n",
    "    texto = unicodedata.normalize('NFKD', \"\".join(n_str))\n",
    "    texto = re.sub(r'(\\s)+', r' ', texto.strip(), flags=re.IGNORECASE)\n",
    "    return texto\n",
    "\n",
    "\n",
    "# Preprocesamiento personalizado \n",
    "def mi_preprocesamiento(texto):\n",
    "    #convierte a minúsculas el texto antes de normalizar\n",
    "    tokens = word_tokenize(texto.lower())\n",
    "    texto = \" \".join(tokens)\n",
    "    texto = normaliza_texto(texto)\n",
    "    return texto\n",
    "    \n",
    "# Tokenizador personalizado \n",
    "def mi_tokenizador(texto):\n",
    "    # Elimina stopwords: palabras que no se consideran de contenido y que no agregan valor semántico al texto\n",
    "    #print(\"antes: \", texto)\n",
    "    texto = [t for t in texto.split() if t not in _STOPWORDS]\n",
    "    #print(\"después:\",texto)\n",
    "    return texto\n",
    "\n",
    "\n",
    "vec_tfidf = TfidfVectorizer(analyzer=\"word\", preprocessor=mi_preprocesamiento, tokenizer=mi_tokenizador,  ngram_range=(1,1))\n",
    "X_train_tfidf = vec_tfidf.fit_transform(X_train)\n",
    "X_train_tfidf = X_train_tfidf.toarray()\n",
    "\n",
    "print(\"vocabulario: \", len(vec_tfidf.get_feature_names_out()))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_val_tfidf = vec_tfidf.transform(X_val)\n",
    "X_val_tfidf= X_val_tfidf.toarray()\n",
    "Y_train = Y_train[:, np.newaxis] # Agregar una dimensión adicional para representar 1 ejemplo de entrenamiento por fila\n",
    "Y_val = Y_val[:, np.newaxis] # Agregar una dimensión adicional para representar 1 ejemplo de entrenamiento por fila\n",
    "\n",
    "print(Y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Definición de la arquitectura de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import numpy as np\n",
    "# Definir la red neuronal en PyTorch heredando de la clase base de Redes Neuronales: Module\n",
    "class RedNeuronal(nn.Module):\n",
    "    def __init__(self, tam_entrada, tam_capa_oculta, tam_salida, tasa_reduccion = 0.3):\n",
    "        super().__init__()\n",
    "        # Redondeado hacia arriba, reducir con la tasa de reducción \"reduction_rate\"\n",
    "        self.tam_capa_oculta2 = int(tam_capa_oculta - np.ceil(tam_capa_oculta * tasa_reduccion))\n",
    "        # print(f\"tamaño capa oculta2: {self.tam_capa_oculta2 }\")\n",
    "\n",
    "        # Definición de capas, funciones de activación e inicialización de pesos\n",
    "        # Capa Fully Connected (Capa Totalmente Conectada)\n",
    "        self.fc1 = nn.Linear(tam_entrada, tam_capa_oculta)\n",
    "        self.fc2 = nn.Linear(tam_capa_oculta, self.tam_capa_oculta2)\n",
    "        self.fc3 = nn.Linear(self.tam_capa_oculta2, tam_salida)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.tam_capa_1_pesos = tam_entrada * tam_capa_oculta \n",
    "        self.tam_capa_1_bias  =  tam_capa_oculta # bias \n",
    "        self.tam_capa_2_pesos = tam_capa_oculta * self.tam_capa_oculta2 \n",
    "        self.tam_capa_2_bias =  self.tam_capa_oculta2 # bias \n",
    "        self.tam_capa_3_pesos = self.tam_capa_oculta2 * tam_salida\n",
    "        self.tam_capa_3_bias =  tam_salida # bias \n",
    "        self.tam_individuo = int(self.tam_capa_1_pesos + self.tam_capa_1_bias  +  self.tam_capa_2_pesos + self.tam_capa_2_bias + self.tam_capa_3_pesos + self.tam_capa_3_bias)\n",
    "        # print(f\"tamaño individuo (genoma): {self.tam_individuo  }\")\n",
    "\n",
    "    def forward(self, X):\n",
    "        # Definición del orden de conexión de las capas y aplición de las funciones de activación\n",
    "        out = self.fc1(X)\n",
    "        out = self.relu(out)  # Aplicamos la función de activación\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)  # Aplicamos la función de activación\n",
    "        out = self.fc3(out)\n",
    "        out = self.softmax(out)  # Aplicamos la activación softmax para obtenr la probabilidad de cada neurona de salida\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Definición del algoritmo evolutivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "def inicializar_poblacion(tam_poblacion, tam_entrada, tam_capa_oculta, tam_salida, tasa_reduccion):\n",
    "    # Cada individuo es del tamaño del total de los pesos y bias que conforman a la red neuronal\n",
    "    # Un individuo está formado por los pesos y bias de todas sus capas en forma de un vector\n",
    "    # indviduo = [w11(1), w12(1), w13(1), b1(1), b2(1), w11(2), w12(2, b1(2), b2(2), ....]\n",
    "    # w11(1) representa el peso w11 de la capa 1\n",
    "    # wij(n) representa un peso i,j de la capa n\n",
    "    # bk(n) representa un sesgo (bias) k de la capa n\n",
    "    \n",
    "    red = RedNeuronal(tam_entrada, tam_capa_oculta, tam_salida, tasa_reduccion)    \n",
    "    tam_individuo = red.tam_individuo\n",
    "    poblacion = np.random.uniform(low=-0.5, high=0.5, size=(tam_poblacion, tam_individuo))\n",
    "    return poblacion\n",
    "    \n",
    "\n",
    "\n",
    "#  Función para evaluar el individuo (que representa su genoma)\n",
    "def funcion_fitness(individuo, X, Y, tam_entrada, tam_capa_oculta, tam_salida, tasa_reduccion):\n",
    "    model = RedNeuronal(tam_entrada, tam_capa_oculta, tam_salida, tasa_reduccion)\n",
    "    \n",
    "    # Cargar pesos del individuo\n",
    "    with torch.no_grad():\n",
    "        # La matriz de pesos en Pytorch tienen la forma transpuesta (salida, entradas) a la inversa como se define la capa Lineal\n",
    "        model.fc1.weight.data = torch.from_numpy(individuo[:model.tam_capa_1_pesos].reshape(tam_capa_oculta, tam_entrada)).float()\n",
    "        desplazamiento_capa_1 =   model.tam_capa_1_pesos + model.tam_capa_1_bias\n",
    "        model.fc1.bias.data = torch.from_numpy(individuo[model.tam_capa_1_pesos:desplazamiento_capa_1]).float()\n",
    "        \n",
    "        model.fc2.weight.data = torch.from_numpy(individuo[desplazamiento_capa_1:desplazamiento_capa_1 + model.tam_capa_2_pesos].reshape(model.tam_capa_oculta2, tam_capa_oculta)).float()\n",
    "        \n",
    "        desplazamiento_capa_2 = desplazamiento_capa_1 + model.tam_capa_2_pesos + model.tam_capa_2_bias\n",
    "        model.fc2.bias.data = torch.from_numpy(individuo[desplazamiento_capa_1 + model.tam_capa_2_pesos:desplazamiento_capa_2]).float()\n",
    "        \n",
    "        model.fc3.weight.data = torch.from_numpy(individuo[desplazamiento_capa_2:desplazamiento_capa_2 + model.tam_capa_3_pesos].reshape(tam_salida, model.tam_capa_oculta2)).float()\n",
    "        \n",
    "        desplazamiento_capa_3 = desplazamiento_capa_2 + model.tam_capa_3_pesos + model.tam_capa_3_bias\n",
    "        model.fc3.bias.data = torch.from_numpy(individuo[desplazamiento_capa_2 + model.tam_capa_3_pesos:desplazamiento_capa_3]).float()\n",
    "\n",
    "    \n",
    "    # Calcular precisión\n",
    "\n",
    "    X_tensor = torch.from_numpy(X).float()\n",
    "    # Y_tensor = torch.from_numpy(Y).float()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_tensor)\n",
    "        # Obtiene una única clase, la más probable\n",
    "        y_pred = torch.argmax(y_pred, dim=1)\n",
    "        # _, y_pred = torch.max(outputs.data, dim=1)\n",
    "        # print(y_pred)\n",
    "        score = f1_score(Y, y_pred, average=\"macro\")\n",
    "            \n",
    "    return score\n",
    "\n",
    "def evaluar_fitness(poblacion,  X, Y, tam_entrada, tam_capa_oculta, tam_salida, tasa_reduccion):\n",
    "    fitness = []\n",
    "    for individuo in poblacion:\n",
    "        val_fitness = funcion_fitness(individuo, X, Y, tam_entrada, tam_capa_oculta, tam_salida, tasa_reduccion)\n",
    "        fitness.append(val_fitness)\n",
    "    return  np.array(fitness)\n",
    "\n",
    "    \n",
    "#------------------------------------------------------------------------\n",
    "def seleccionar_padres(poblacion, aptitudes):\n",
    "    \"\"\"Selecciona dos padres mediante torneo.\"\"\"\n",
    "    torneo = random.sample(list(zip(poblacion, aptitudes)), k=4)\n",
    "    torneo.sort(key=lambda x: x[1])  \n",
    "    return torneo[0][0], torneo[1][0]\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "def elitismo(poblacion, fitness, tam_elite=2):\n",
    "    \"\"\"Selecciona los 'tam_elite' mejores best_individuos.\"\"\"\n",
    "    # Ordenar por fitness (mayor = mejor)\n",
    "    ranked_indices = np.argsort(fitness)[::-1]\n",
    "    elites = [poblacion[i] for i in ranked_indices[:tam_elite]]\n",
    "    return elites\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "def cruzar(padre1, padre2):\n",
    "    punto_cruza = np.random.randint(len(padre1))\n",
    "    hijo1 = np.concatenate([padre1[:punto_cruza], padre2[punto_cruza:]])\n",
    "    hijo2 = np.concatenate([padre2[:punto_cruza], padre1[punto_cruza:]])\n",
    "    return hijo1, hijo2\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "def mutar(individuo, tasa_mutacion=0.1):\n",
    "    # Crea la mascara de genes por mutar que cumplan con la condición\n",
    "    mascara = np.random.rand(len(individuo)) < tasa_mutacion\n",
    "    individuo = mascara * np.random.normal(0, 1, size=len(individuo))  # Mutar al individuo en los genes seleccionados \n",
    "    return individuo\n",
    "\n",
    "\n",
    "    \n",
    "def algoritmo_evolutivo(X, Y, tam_poblacion=30, num_generaciones=50):\n",
    "    tam_entrada = X.shape[1] # Características TF-IDF, columnas\n",
    "    tam_capa_oculta = 128\n",
    "    tam_salida = 3  # 3 categorías\n",
    "    tasa_reduccion = 0.3\n",
    "        \n",
    "    # Población inicial\n",
    "    poblacion = inicializar_poblacion(tam_poblacion, tam_entrada, tam_capa_oculta, tam_salida, tasa_reduccion)\n",
    "    best_fitness_hist = []\n",
    "    mean_fitness_hist = []\n",
    "\n",
    "    for generacion in range(num_generaciones):\n",
    "        # Evaluar fitness (usando el conjunto de entrenamiento)\n",
    "        val_fitness = evaluar_fitness(poblacion,  X, Y, tam_entrada, tam_capa_oculta, tam_salida, tasa_reduccion)\n",
    "        \n",
    "        # Registrar estadísticas\n",
    "        print(\"obteniendo mejor fitness\" )\n",
    "        best_fitness = np.max(val_fitness)\n",
    "        print(\"obteniendo media fitness \" )\n",
    "        mean_fitness = np.mean(val_fitness)\n",
    "        best_fitness_hist.append(best_fitness)\n",
    "        mean_fitness_hist.append(mean_fitness)\n",
    "        \n",
    "        print(f\"Generación {generacion + 1}: Mejor fitness = {best_fitness:.4f}, Fitness promedio = {mean_fitness:.4f}\")\n",
    "        nueva_poblacion = []\n",
    "\n",
    "        for _ in range(tam_poblacion // 2):\n",
    "            # Seleccionar padres\n",
    "            padre1, padre2 = seleccionar_padres(poblacion, val_fitness)            \n",
    "            # Crear descendencia mediante cruce\n",
    "            hijo1, hijo2 = cruzar(padre1, padre2)\n",
    "            hijo1 = mutar(hijo1)\n",
    "            hijo2 = mutar(hijo2)\n",
    "            nueva_poblacion.append(hijo1)            \n",
    "            nueva_poblacion.append(hijo2)        \n",
    "        \n",
    "        \n",
    "        #-----------------\n",
    "        # Población: Los hijos sustituyen a los padres\n",
    "        #-----------------\n",
    "        # poblacion = np.array(nueva_poblacion)\n",
    "    \n",
    "        #-----------------\n",
    "        # Población con elitismo de padres y parte de los hijos\n",
    "        #-----------------\n",
    "        nueva_poblacion = np.array(nueva_poblacion)\n",
    "        K_best_padres = 5\n",
    "        poblacion[:K_best_padres, ] = elitismo(poblacion, val_fitness, K_best_padres)\n",
    "        poblacion[K_best_padres:, ] = nueva_poblacion[K_best_padres:, ]\n",
    "\n",
    "\n",
    "    val_fitness = evaluar_fitness(poblacion,  X, Y, tam_entrada, tam_capa_oculta, tam_salida, tasa_reduccion)\n",
    "\n",
    "    # Evaluar el mejor modelo en train\n",
    "    best_individuo = poblacion[np.argmax(val_fitness)]\n",
    "    test_f1 = funcion_fitness(best_individuo, X, Y, tam_entrada, tam_capa_oculta, tam_salida, tasa_reduccion)\n",
    "    print(f\"\\nF1-score final en test: {test_f1:.3f}\")\n",
    "    return best_individuo\n",
    "\n",
    "\n",
    "def predecir_clase(individuo, X, tam_entrada, tam_capa_oculta, tam_salida, tasa_reduccion):\n",
    "    model = RedNeuronal(tam_entrada, tam_capa_oculta, tam_salida, tasa_reduccion)\n",
    "    \n",
    "    # Cargar pesos del individuo\n",
    "    with torch.no_grad():\n",
    "        # La matriz de pesos en Pytorch tienen la forma transpuesta (salida, entradas) a la inversa como se define la capa Lineal\n",
    "        model.fc1.weight.data = torch.from_numpy(individuo[:model.tam_capa_1_pesos].reshape(tam_capa_oculta, tam_entrada)).float()\n",
    "        desplazamiento_capa_1 =   model.tam_capa_1_pesos + model.tam_capa_1_bias\n",
    "        model.fc1.bias.data = torch.from_numpy(individuo[model.tam_capa_1_pesos:desplazamiento_capa_1]).float()\n",
    "        \n",
    "        model.fc2.weight.data = torch.from_numpy(individuo[desplazamiento_capa_1:desplazamiento_capa_1 + model.tam_capa_2_pesos].reshape(model.tam_capa_oculta2, tam_capa_oculta)).float()\n",
    "        \n",
    "        desplazamiento_capa_2 = desplazamiento_capa_1 + model.tam_capa_2_pesos + model.tam_capa_2_bias\n",
    "        model.fc2.bias.data = torch.from_numpy(individuo[desplazamiento_capa_1 + model.tam_capa_2_pesos:desplazamiento_capa_2]).float()\n",
    "        \n",
    "        model.fc3.weight.data = torch.from_numpy(individuo[desplazamiento_capa_2:desplazamiento_capa_2 + model.tam_capa_3_pesos].reshape(tam_salida, model.tam_capa_oculta2)).float()\n",
    "        \n",
    "        desplazamiento_capa_3 = desplazamiento_capa_2 + model.tam_capa_3_pesos + model.tam_capa_3_bias\n",
    "        model.fc3.bias.data = torch.from_numpy(individuo[desplazamiento_capa_2 + model.tam_capa_3_pesos:desplazamiento_capa_3]).float()\n",
    "\n",
    "    \n",
    "    # Calcular precisión\n",
    "    X_tensor = torch.from_numpy(X).float()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_tensor)\n",
    "        y_pred = torch.argmax(y_pred, dim=1)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Ejecución del algoritmo evolutivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obteniendo mejor fitness\n",
      "obteniendo media fitness \n",
      "Generación 1: Mejor fitness = 0.3533, Fitness promedio = 0.2586\n",
      "obteniendo mejor fitness\n",
      "obteniendo media fitness \n",
      "Generación 2: Mejor fitness = 0.3533, Fitness promedio = 0.2623\n",
      "obteniendo mejor fitness\n",
      "obteniendo media fitness \n",
      "Generación 3: Mejor fitness = 0.3533, Fitness promedio = 0.2652\n",
      "obteniendo mejor fitness\n",
      "obteniendo media fitness \n",
      "Generación 4: Mejor fitness = 0.3611, Fitness promedio = 0.2614\n",
      "obteniendo mejor fitness\n",
      "obteniendo media fitness \n",
      "Generación 5: Mejor fitness = 0.3611, Fitness promedio = 0.2574\n",
      "obteniendo mejor fitness\n",
      "obteniendo media fitness \n",
      "Generación 6: Mejor fitness = 0.3669, Fitness promedio = 0.2672\n",
      "obteniendo mejor fitness\n",
      "obteniendo media fitness \n",
      "Generación 7: Mejor fitness = 0.3669, Fitness promedio = 0.2570\n",
      "obteniendo mejor fitness\n",
      "obteniendo media fitness \n",
      "Generación 8: Mejor fitness = 0.3669, Fitness promedio = 0.2683\n",
      "obteniendo mejor fitness\n",
      "obteniendo media fitness \n",
      "Generación 9: Mejor fitness = 0.3999, Fitness promedio = 0.2772\n",
      "obteniendo mejor fitness\n",
      "obteniendo media fitness \n",
      "Generación 10: Mejor fitness = 0.3999, Fitness promedio = 0.2621\n",
      "obteniendo mejor fitness\n",
      "obteniendo media fitness \n",
      "Generación 11: Mejor fitness = 0.3999, Fitness promedio = 0.2532\n",
      "obteniendo mejor fitness\n",
      "obteniendo media fitness \n",
      "Generación 12: Mejor fitness = 0.3999, Fitness promedio = 0.2616\n",
      "obteniendo mejor fitness\n",
      "obteniendo media fitness \n",
      "Generación 13: Mejor fitness = 0.3999, Fitness promedio = 0.2597\n",
      "obteniendo mejor fitness\n",
      "obteniendo media fitness \n",
      "Generación 14: Mejor fitness = 0.3999, Fitness promedio = 0.2624\n",
      "obteniendo mejor fitness\n",
      "obteniendo media fitness \n",
      "Generación 15: Mejor fitness = 0.3999, Fitness promedio = 0.2741\n",
      "obteniendo mejor fitness\n",
      "obteniendo media fitness \n",
      "Generación 16: Mejor fitness = 0.3999, Fitness promedio = 0.2733\n",
      "obteniendo mejor fitness\n",
      "obteniendo media fitness \n",
      "Generación 17: Mejor fitness = 0.3999, Fitness promedio = 0.2641\n",
      "obteniendo mejor fitness\n",
      "obteniendo media fitness \n",
      "Generación 18: Mejor fitness = 0.3999, Fitness promedio = 0.2794\n",
      "obteniendo mejor fitness\n",
      "obteniendo media fitness \n",
      "Generación 19: Mejor fitness = 0.3999, Fitness promedio = 0.2702\n",
      "obteniendo mejor fitness\n",
      "obteniendo media fitness \n",
      "Generación 20: Mejor fitness = 0.3999, Fitness promedio = 0.2583\n",
      "obteniendo mejor fitness\n",
      "obteniendo media fitness \n",
      "Generación 21: Mejor fitness = 0.3999, Fitness promedio = 0.2674\n",
      "obteniendo mejor fitness\n",
      "obteniendo media fitness \n",
      "Generación 22: Mejor fitness = 0.3999, Fitness promedio = 0.2553\n",
      "obteniendo mejor fitness\n",
      "obteniendo media fitness \n",
      "Generación 23: Mejor fitness = 0.3999, Fitness promedio = 0.2680\n",
      "obteniendo mejor fitness\n",
      "obteniendo media fitness \n",
      "Generación 24: Mejor fitness = 0.3999, Fitness promedio = 0.2706\n",
      "obteniendo mejor fitness\n",
      "obteniendo media fitness \n",
      "Generación 25: Mejor fitness = 0.3999, Fitness promedio = 0.2642\n",
      "obteniendo mejor fitness\n",
      "obteniendo media fitness \n",
      "Generación 26: Mejor fitness = 0.3999, Fitness promedio = 0.2708\n",
      "obteniendo mejor fitness\n",
      "obteniendo media fitness \n",
      "Generación 27: Mejor fitness = 0.3999, Fitness promedio = 0.2773\n",
      "obteniendo mejor fitness\n",
      "obteniendo media fitness \n",
      "Generación 28: Mejor fitness = 0.3999, Fitness promedio = 0.2607\n",
      "obteniendo mejor fitness\n",
      "obteniendo media fitness \n",
      "Generación 29: Mejor fitness = 0.3999, Fitness promedio = 0.2777\n",
      "obteniendo mejor fitness\n",
      "obteniendo media fitness \n",
      "Generación 30: Mejor fitness = 0.3999, Fitness promedio = 0.2805\n",
      "obteniendo mejor fitness\n",
      "obteniendo media fitness \n",
      "Generación 31: Mejor fitness = 0.3999, Fitness promedio = 0.2618\n",
      "obteniendo mejor fitness\n",
      "obteniendo media fitness \n",
      "Generación 32: Mejor fitness = 0.3999, Fitness promedio = 0.2603\n",
      "obteniendo mejor fitness\n",
      "obteniendo media fitness \n",
      "Generación 33: Mejor fitness = 0.3999, Fitness promedio = 0.2631\n",
      "obteniendo mejor fitness\n",
      "obteniendo media fitness \n",
      "Generación 34: Mejor fitness = 0.3999, Fitness promedio = 0.2636\n",
      "obteniendo mejor fitness\n",
      "obteniendo media fitness \n",
      "Generación 35: Mejor fitness = 0.3999, Fitness promedio = 0.2671\n",
      "obteniendo mejor fitness\n",
      "obteniendo media fitness \n",
      "Generación 36: Mejor fitness = 0.3999, Fitness promedio = 0.2820\n",
      "obteniendo mejor fitness\n",
      "obteniendo media fitness \n",
      "Generación 37: Mejor fitness = 0.3999, Fitness promedio = 0.2704\n",
      "obteniendo mejor fitness\n",
      "obteniendo media fitness \n",
      "Generación 38: Mejor fitness = 0.3999, Fitness promedio = 0.2622\n",
      "obteniendo mejor fitness\n",
      "obteniendo media fitness \n",
      "Generación 39: Mejor fitness = 0.3999, Fitness promedio = 0.2702\n",
      "obteniendo mejor fitness\n",
      "obteniendo media fitness \n",
      "Generación 40: Mejor fitness = 0.3999, Fitness promedio = 0.2522\n",
      "obteniendo mejor fitness\n",
      "obteniendo media fitness \n",
      "Generación 41: Mejor fitness = 0.3999, Fitness promedio = 0.2644\n",
      "obteniendo mejor fitness\n",
      "obteniendo media fitness \n",
      "Generación 42: Mejor fitness = 0.3999, Fitness promedio = 0.2774\n",
      "obteniendo mejor fitness\n",
      "obteniendo media fitness \n",
      "Generación 43: Mejor fitness = 0.3999, Fitness promedio = 0.2641\n",
      "obteniendo mejor fitness\n",
      "obteniendo media fitness \n",
      "Generación 44: Mejor fitness = 0.3999, Fitness promedio = 0.2636\n",
      "obteniendo mejor fitness\n",
      "obteniendo media fitness \n",
      "Generación 45: Mejor fitness = 0.3999, Fitness promedio = 0.2491\n",
      "obteniendo mejor fitness\n",
      "obteniendo media fitness \n",
      "Generación 46: Mejor fitness = 0.3999, Fitness promedio = 0.2742\n",
      "obteniendo mejor fitness\n",
      "obteniendo media fitness \n",
      "Generación 47: Mejor fitness = 0.3999, Fitness promedio = 0.2601\n",
      "obteniendo mejor fitness\n",
      "obteniendo media fitness \n",
      "Generación 48: Mejor fitness = 0.3999, Fitness promedio = 0.2724\n",
      "obteniendo mejor fitness\n",
      "obteniendo media fitness \n",
      "Generación 49: Mejor fitness = 0.3999, Fitness promedio = 0.2686\n",
      "obteniendo mejor fitness\n",
      "obteniendo media fitness \n",
      "Generación 50: Mejor fitness = 0.3999, Fitness promedio = 0.2685\n",
      "\n",
      "F1-score final en test: 0.400\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_individuo = algoritmo_evolutivo(X_train_tfidf, Y_train, tam_poblacion=50, num_generaciones=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Prueba del mejor individuo en el conjunto de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "tam_entrada = len(vec_tfidf.get_feature_names_out()) # Características TF-IDF\n",
    "tam_capa_oculta = 128\n",
    "tam_salida = 3  # 3 categorías\n",
    "tasa_reduccion = 0.3\n",
    "\n",
    "dataset_test = pd.read_json(\"./data/dataset_polaridad_es_test.json\", lines=True)\n",
    "#conteo de clases\n",
    "print(\"Total de ejemplos de entrenamiento\")\n",
    "print(dataset_test.klass.value_counts())\n",
    "# Extracción de los textos en arreglos de numpy\n",
    "X_test = dataset_test['text'].to_numpy()\n",
    "# Extracción de las etiquetas o clases de entrenamiento\n",
    "Y_test = dataset_test['klass'].to_numpy()\n",
    "\n",
    "X_test_tfidf = vec_tfidf.transform(X_test)\n",
    "X_test_tfidf = X_test_tfidf.toarray()\n",
    "Y_test = le.transform(Y_test)\n",
    "Y_t = Y_test[:, np.newaxis] # Agregar una dimensión adicional para representar 1 ejemplo de entrenamiento por fila\n",
    "y_pred_test = predecir_clase(best_individuo, X_test_tfidf, tam_entrada, tam_capa_oculta, tam_salida, tasa_reduccion)\n",
    "print(Y_t[:5])\n",
    "print(y_pred_test[:5])\n",
    "score = f1_score(Y_t, y_pred_test, average=\"macro\")\n",
    "print(f\"\\nF1-score final en test: {score:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicción de datos nuevos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tam_entrada = len(vec_tfidf.get_feature_names_out()) # Características TF-IDF\n",
    "tam_capa_oculta = 128\n",
    "tam_salida = 3  # 3 categorías\n",
    "tasa_reduccion = 0.3\n",
    "\n",
    "\n",
    "ejemplos_nuevos = [\"Que tristeza es no tener celular\"]\n",
    "# Suponer que se cuenta con el objeto vec_tfidf entrenado con el vocabulario del conjunto de entrenamiento\n",
    "X_ejemplos_tfidf = vec_tfidf.transform(ejemplos_nuevos)\n",
    "X_ejemplos_tfidf = X_ejemplos_tfidf.toarray()\n",
    "y_pred_nuevo = predecir_clase(best_individuo, X_ejemplos_tfidf, tam_entrada, tam_capa_oculta, tam_salida, tasa_reduccion)\n",
    "print(y_pred_nuevo)\n",
    "y_pred_nuevo = y_pred_nuevo.flatten()\n",
    "print(le.inverse_transform(y_pred_nuevo))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Evaluando el desempeño"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métricas de Evaluación\n",
    " - #### Las métricas precisión, recall y F1 son fundamentales para evaluar el rendimiento de un clasificador\n",
    "\n",
    "\n",
    "<img src=\"figs/fig_precision-recall.png\" width=\"300\">\n",
    "\n",
    "##### Fuente: https://en.wikipedia.org/wiki/Precision_and_recall\n",
    "\n",
    "\n",
    "<img src=\"figs/fig_matriz-confusion.png\" width=\"500\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TP=True Positive\n",
    "\n",
    "TN=True Negative\n",
    "\n",
    "FP=False Positive (Error tipo I: ejemplo, se considera que el paciente está enfermo, pero en realidad está sano)\n",
    "\n",
    "FN=False Negative ( Error tipo II: ejemplo, se considera que el paciente está sano, pero en realidad está enfermo)\n",
    "\n",
    "\n",
    "$$ Accuracy = \\frac{total~ TP + total~TN}{total~muestras} $$\n",
    "\n",
    "$$ Precision_c = \\frac{ TP_c}{TP_c + FP_c} $$\n",
    "\n",
    "$$ Recall_c = \\frac{ TP_c}{TP_c + FN_c} $$\n",
    "\n",
    "$$ F1-score_c= 2 \\times \\frac{ Precision_c \\times Recall_c}{Precision_c + Recall_c} $$\n",
    "\n",
    "$$ macro-F1-score= \\frac{ 1 }{|Clases|} \\sum{F1-score_c} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "ConfusionMatrixDisplay.from_predictions(Y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "print(\"P=\", precision_score(Y_test, y_pred_test, average='macro'))\n",
    "print(\"R=\", recall_score(Y_test, y_pred_test, average='macro'))\n",
    "print(\"F1=\", f1_score(Y_test, y_pred_test, average='macro'))\n",
    "print(\"Acc=\", accuracy_score(Y_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métricas de la clase 0, la precisión es la siguiente\n",
    "tp= 47\n",
    "fp = 79+48\n",
    "tp/(tp + fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspección del desempeño por clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(Y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, y_pred_test, digits=4, zero_division='warn'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Probar diferentes tipos de preprocesamiento para ver el impacto en el rendimiento de los invidividuos evolucionandos:\n",
    "- ### Preprocesamiento con Unigramas, bigramas, trigramas\n",
    "- ### Stemming vs sin Stemming\n",
    "- ### Porcentaje de features máximas (20, 30, 40)%\n",
    "### 2. Probar diferentes tipos de operadores de variación:\n",
    "- ### Cruza (1 punto, 2 puntos, n puntos)\n",
    "### 3. Variar el tamaño de la población (considerar que en estos casos el costo computacional es mayor)\n",
    "### 4. Variar el número de generaciones (considerar que en estos casos el costo computacional es mayor)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
