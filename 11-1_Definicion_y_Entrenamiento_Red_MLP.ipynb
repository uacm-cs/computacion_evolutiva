{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementar un Multilayer Perceptron  con PyTorch para clasificación de texto\n",
    "# Uso de word embeddings como representación de datos\n",
    "\n",
    "\n",
    "<img src=\"figs/fig-diagrama-clasificador2.png\" width=\"900\">\n",
    "\n",
    "\n",
    "### 1. **Representar los datos en el modelo de word embeddings seleccionado**:  \n",
    "   - #### Generalmente, solo se tokeniza para separar adecuadamente las palabras.\n",
    "   - #### Sin embargo, dependiendo del modelos de word embeddings algunos preprocesamientos puede mejorar la representación.\n",
    "   - #### Por ejemplo: \n",
    "      - ##### tokenizar y separar correctamente las oraciones y palabras\n",
    "      - ##### convertir a minúsculas\n",
    "      - ##### quitar acentos (dependiendo de la fuente de datos con la que se generaros los embeddings)\n",
    "      - ##### quitar números y puntuación \n",
    "\n",
    "\n",
    "### 3. **Convertir los datos a vectores densos: word embeddings**:  \n",
    "   - #### En el caso de textos corto a nivel de oración, un vector denso por oración. \n",
    "\n",
    "### 4. **Separar los datos para entrenamiento, validación y prueba**:  \n",
    "   - #### Crear los dataset  con la función train_test_split \n",
    "   \n",
    "### 5. **Definir la arquitectura de la red**:  \n",
    "   - Definir una red de 2 capas, con funciones PReLU en las capas ocultas y una capa de salida\n",
    "\n",
    "### 6. **Entrenar el modelo**:  \n",
    "   - Definir los parámetros de las red como: número de épocas, learning_rate, número de neuronas para las capas ocultas, etc.\n",
    "   \n",
    "### 7. **Evaluar el modelo**:  \n",
    "   - Después del entrenamiento, probar la red con las entradas del conjunto de test y evaluar el desempeño con las métricas: Precisión, Recall, F1-score o F1-Measure y Accuracy.\n",
    "   \n",
    "\n",
    "### 8. **Guardar el modelo**:  \n",
    "   - Después del entrenamiento, el modelo se guarda para posteriores usos: despliegue del modelo para aplicación web, o como punto de partida para optimizar por medio de Computación Evolutiva.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar los datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de ejemplos de entrenamiento\n",
      "klass\n",
      "neutral     1485\n",
      "positive     968\n",
      "negative     689\n",
      "Name: count, dtype: int64\n",
      "Datos train: (3142, 300)\n",
      "Etiquetas train: (3142,)\n",
      "Datos test: (786, 300)\n",
      "Etiquetas test: (786,)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# colocar la semilla para la generación de números aleatorios para la reproducibilidad de experimentos\n",
    "\n",
    "random_state = 42\n",
    "torch.manual_seed(random_state)\n",
    "np.random.seed(random_state)\n",
    "\n",
    "#cargar los datos\n",
    "dataset_train = pd.read_json(\"./data/dataset_polaridad_es_train_embeddings.json\", lines=True)\n",
    "dataset_test = pd.read_json(\"./data/dataset_polaridad_es_test_embeddings.json\", lines=True)\n",
    "\n",
    "#conteo de clases\n",
    "print(\"Total de ejemplos de entrenamiento\")\n",
    "print(dataset_train.klass.value_counts())\n",
    "# Extracción de los vectores de embeddings que representan a los textos\n",
    "X = np.vstack(dataset_train['we_es'].to_numpy())\n",
    "# Extracción de las etiquetas o clases de entrenamiento\n",
    "Y = dataset_train['klass'].to_numpy()\n",
    "\n",
    "X_test = np.vstack(dataset_test['we_es'].to_numpy())\n",
    "# Extracción de las etiquetas o clases de entrenamiento\n",
    "Y_test = dataset_test['klass'].to_numpy()\n",
    "\n",
    "\n",
    "print(\"Datos train:\", X.shape) \n",
    "print(\"Etiquetas train:\", Y.shape) \n",
    "print(\"Datos test:\", X_test.shape) \n",
    "print(\"Etiquetas test:\", Y_test.shape) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codificar las etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases:\n",
      "['negative' 'neutral' 'positive']\n",
      "Clases codificadas:\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Codificar las etiquetas de los datos a una forma categórica numérica: LabelEncoder.\n",
    "\n",
    "le = LabelEncoder()\n",
    "# Normalizar las etiquetas a una codificación ordinal para entrada del clasificador\n",
    "Y_train_encoded= le.fit_transform(Y)\n",
    "print(\"Clases:\")\n",
    "print(le.classes_)\n",
    "print(\"Clases codificadas:\")\n",
    "print(le.transform(le.classes_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparar los conjuntos de datos  para el entrenamiento, validación y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dividir el conjunto de entrenamiento en:  entrenamiento (80%) y validación (10%)\n",
    "X_train, X_val, Y_train, Y_val =  train_test_split(X, Y_train_encoded, test_size=0.1, stratify=Y_train_encoded, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Codificar las clases en forma one-hot \n",
    "NUM_CLASSES = 3\n",
    "Y_train_one_hot = nn.functional.one_hot(torch.from_numpy(Y_train), num_classes=NUM_CLASSES).float()\n",
    "\n",
    "\n",
    "# Crear minibatches en PyTorch usando DataLoader\n",
    "def create_minibatches(X, Y, batch_size):\n",
    "    # Recibe los documentos en X y las etiquetas en Y\n",
    "    dataset = TensorDataset(X, Y) # Cargar los datos en un dataset de tensores\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    # loader = DataLoader(dataset, batch_size=batch_size)\n",
    "    return loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2827, 300), (2827,), (315, 300), (315,), (786, 300), (786,))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, Y_train.shape, X_val.shape, Y_val.shape, X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 1., 0.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 0., 1.]]),\n",
       " torch.Size([2827, 3]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_one_hot[:5],  Y_train_one_hot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición de la arquitectura de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Definir la red neuronal en PyTorch heredando de la clase base de Redes Neuronales: Module\n",
    "class RedNeuronal(nn.Module):\n",
    "    def __init__(self, tam_entrada, tam_salida):\n",
    "        super().__init__()\n",
    "        # Definición de capas, funciones de activación e inicialización de pesos\n",
    "        tam_entrada_capa_oculta_1 = 128\n",
    "        tam_entrada_capa_oculta_2 = 8 \n",
    "        self.fc1 = nn.Linear(tam_entrada, tam_entrada_capa_oculta_1)\n",
    "        self.fc2 = nn.Linear(tam_entrada_capa_oculta_1, tam_entrada_capa_oculta_2)\n",
    "        self.salida = nn.Linear(tam_entrada_capa_oculta_2, tam_salida)\n",
    "        self.activacion= nn.PReLU()\n",
    "\n",
    "        nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        nn.init.xavier_uniform_(self.fc2.weight)\n",
    "        nn.init.xavier_uniform_(self.salida.weight)\n",
    "\n",
    "        if self.fc1.bias is not None:\n",
    "            nn.init.zeros_(self.fc1.bias)\n",
    "        if self.fc2.bias is not None:\n",
    "            nn.init.zeros_(self.fc2.bias)        \n",
    "        if self.salida.bias is not None:\n",
    "            nn.init.zeros_(self.salida.bias)        \n",
    "\n",
    "    \n",
    "    def forward(self, X):\n",
    "        # Definición del orden de conexión de las capas y aplición de las funciones de activación\n",
    "        x = self.fc1(X)\n",
    "        x = self.activacion(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.activacion(x)\n",
    "        x = self.salida(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando entrenamiento en PyTorch\n",
      "Batch Error : 1.0525912046432495\n",
      "Batch Error : 0.9963858723640442\n",
      "Época 1/30, Pérdida: 1.0407793133155159\n",
      "Época 1/30\n",
      "P= 0.495114006514658\n",
      "R= 0.36082474226804123\n",
      "F1= 0.26862990810359233\n",
      "Acc= 0.4984126984126984\n",
      "Batch Error : 1.011348009109497\n",
      "Batch Error : 1.0457382202148438\n",
      "Batch Error : 0.9891188144683838\n",
      "Batch Error : 0.9728950262069702\n",
      "Época 2/30, Pérdida: 1.0152599967044333\n",
      "Época 2/30\n",
      "P= 0.4405340592390952\n",
      "R= 0.42076616158121727\n",
      "F1= 0.37095552681557087\n",
      "Acc= 0.546031746031746\n",
      "Batch Error : 0.983300507068634\n",
      "Batch Error : 0.939422607421875\n",
      "Batch Error : 0.8298612236976624\n",
      "Época 3/30, Pérdida: 0.9704341266466223\n",
      "Época 3/30\n",
      "P= 0.4206967434815536\n",
      "R= 0.48430544984893564\n",
      "F1= 0.4375030841352085\n",
      "Acc= 0.5936507936507937\n",
      "Batch Error : 1.034157633781433\n",
      "Batch Error : 0.9757694005966187\n",
      "Batch Error : 0.9536284804344177\n",
      "Época 4/30, Pérdida: 0.939406446788622\n",
      "Época 4/30\n",
      "P= 0.7237542331881954\n",
      "R= 0.489782139074147\n",
      "F1= 0.4405099971022892\n",
      "Acc= 0.5841269841269842\n",
      "Batch Error : 0.8409056663513184\n",
      "Batch Error : 0.8984089493751526\n",
      "Batch Error : 0.8740516901016235\n",
      "Época 5/30, Pérdida: 0.8998724274013353\n",
      "Época 5/30\n",
      "P= 0.5801793872333291\n",
      "R= 0.47046414982964935\n",
      "F1= 0.446702717868362\n",
      "Acc= 0.5746031746031746\n",
      "Batch Error : 0.9313127398490906\n",
      "Época 6/30, Pérdida: 0.8744419916816379\n",
      "Época 6/30\n",
      "P= 0.6103071065049872\n",
      "R= 0.5257738643766519\n",
      "F1= 0.5271093107389048\n",
      "Acc= 0.6063492063492063\n",
      "Batch Error : 0.8321095705032349\n",
      "Batch Error : 0.7867642641067505\n",
      "Época 7/30, Pérdida: 0.8387879677440809\n",
      "Época 7/30\n",
      "P= 0.6502291825821237\n",
      "R= 0.5324515145042853\n",
      "F1= 0.530444521090372\n",
      "Acc= 0.6126984126984127\n",
      "Batch Error : 0.825585663318634\n",
      "Batch Error : 0.8739199638366699\n",
      "Batch Error : 0.8385635614395142\n",
      "Época 8/30, Pérdida: 0.8237450874370077\n",
      "Época 8/30\n",
      "P= 0.6476787346352565\n",
      "R= 0.5306385415193876\n",
      "F1= 0.5383054353030725\n",
      "Acc= 0.6126984126984127\n",
      "Batch Error : 0.868455171585083\n",
      "Batch Error : 0.7568216323852539\n",
      "Batch Error : 0.6957274079322815\n",
      "Época 9/30, Pérdida: 0.7983104975327201\n",
      "Época 9/30\n",
      "P= 0.621259867583397\n",
      "R= 0.5709019841425028\n",
      "F1= 0.5744764825580454\n",
      "Acc= 0.6222222222222222\n",
      "Batch Error : 0.7516723275184631\n",
      "Batch Error : 0.785966694355011\n",
      "Época 10/30, Pérdida: 0.7863028826920883\n",
      "Época 10/30\n",
      "P= 0.6175097397537791\n",
      "R= 0.5268117111904621\n",
      "F1= 0.5291374518611834\n",
      "Acc= 0.6095238095238096\n",
      "Batch Error : 0.6987107396125793\n",
      "Batch Error : 0.6743780970573425\n",
      "Época 11/30, Pérdida: 0.7718690918839496\n",
      "Época 11/30\n",
      "P= 0.6182359307359307\n",
      "R= 0.5891259725426846\n",
      "F1= 0.5989273816541684\n",
      "Acc= 0.6285714285714286\n",
      "Batch Error : 0.7805724740028381\n",
      "Época 12/30, Pérdida: 0.7594308205272841\n",
      "Época 12/30\n",
      "P= 0.5997591522157996\n",
      "R= 0.5769362026705921\n",
      "F1= 0.5847531292298882\n",
      "Acc= 0.6126984126984127\n",
      "Batch Error : 0.7369648218154907\n",
      "Batch Error : 0.7552940845489502\n",
      "Batch Error : 0.6837124824523926\n",
      "Batch Error : 0.8110237717628479\n",
      "Época 13/30, Pérdida: 0.7411867665207904\n",
      "Época 13/30\n",
      "P= 0.5933954208464013\n",
      "R= 0.5727527273979192\n",
      "F1= 0.5795945063432493\n",
      "Acc= 0.6126984126984127\n",
      "Batch Error : 0.7489731907844543\n",
      "Batch Error : 0.7236415147781372\n",
      "Batch Error : 0.7337356209754944\n",
      "Batch Error : 0.7760095000267029\n",
      "Época 14/30, Pérdida: 0.7426848929861317\n",
      "Época 14/30\n",
      "P= 0.6050601214381335\n",
      "R= 0.5877973280708985\n",
      "F1= 0.5941435256560609\n",
      "Acc= 0.6190476190476191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/opt/miniconda3/envs/CE/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/admin/opt/miniconda3/envs/CE/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/admin/opt/miniconda3/envs/CE/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Error : 0.6867101192474365\n",
      "Batch Error : 0.8299028873443604\n",
      "Batch Error : 0.7828238010406494\n",
      "Batch Error : 0.737697422504425\n",
      "Época 15/30, Pérdida: 0.7523205980010654\n",
      "Época 15/30\n",
      "P= 0.6196171570365119\n",
      "R= 0.5933094478153575\n",
      "F1= 0.6020482787403907\n",
      "Acc= 0.6285714285714286\n",
      "Batch Error : 0.784403383731842\n",
      "Batch Error : 0.7127807140350342\n",
      "Batch Error : 0.7598428726196289\n",
      "Época 16/30, Pérdida: 0.7230952408002771\n",
      "Época 16/30\n",
      "P= 0.621268662997189\n",
      "R= 0.592171994447436\n",
      "F1= 0.5991011769603131\n",
      "Acc= 0.6317460317460317\n",
      "Batch Error : 0.7311815023422241\n",
      "Batch Error : 0.8314912915229797\n",
      "Batch Error : 0.6663540601730347\n",
      "Batch Error : 0.7674238085746765\n",
      "Batch Error : 0.6976246237754822\n",
      "Época 17/30, Pérdida: 0.71991526303084\n",
      "Época 17/30\n",
      "P= 0.6236726166144343\n",
      "R= 0.5765137104410732\n",
      "F1= 0.5871997413155949\n",
      "Acc= 0.6253968253968254\n",
      "Batch Error : 0.6435180306434631\n",
      "Batch Error : 0.759217381477356\n",
      "Época 18/30, Pérdida: 0.7212614728056866\n",
      "Época 18/30\n",
      "P= 0.6234201691012322\n",
      "R= 0.586370748295909\n",
      "F1= 0.5972354886001112\n",
      "Acc= 0.6317460317460317\n",
      "Batch Error : 0.6039425134658813\n",
      "Batch Error : 0.7846499681472778\n",
      "Batch Error : 0.7025527954101562\n",
      "Batch Error : 0.6622457504272461\n",
      "Época 19/30, Pérdida: 0.7064596492311229\n",
      "Época 19/30\n",
      "P= 0.6030857824580723\n",
      "R= 0.5868888360773602\n",
      "F1= 0.5927563816588858\n",
      "Acc= 0.6253968253968254\n",
      "Batch Error : 0.7475014925003052\n",
      "Batch Error : 0.8026226758956909\n",
      "Batch Error : 0.6651294827461243\n",
      "Batch Error : 0.662024974822998\n",
      "Batch Error : 0.6622329354286194\n",
      "Época 20/30, Pérdida: 0.7072269605553668\n",
      "Época 20/30\n",
      "P= 0.61961103446522\n",
      "R= 0.5855281035881422\n",
      "F1= 0.5961388074291301\n",
      "Acc= 0.6285714285714286\n",
      "Batch Error : 0.6959131956100464\n",
      "Batch Error : 0.6725027561187744\n",
      "Batch Error : 0.698190450668335\n",
      "Época 21/30, Pérdida: 0.702575973842455\n",
      "Época 21/30\n",
      "P= 0.6123073273025058\n",
      "R= 0.5922716010015473\n",
      "F1= 0.5996042314198153\n",
      "Acc= 0.6253968253968254\n",
      "Batch Error : 0.7447270750999451\n",
      "Batch Error : 0.7080675363540649\n",
      "Época 22/30, Pérdida: 0.6855316628580508\n",
      "Época 22/30\n",
      "P= 0.6324329655903843\n",
      "R= 0.5761908247656655\n",
      "F1= 0.5894376091744513\n",
      "Acc= 0.6317460317460317\n",
      "Batch Error : 0.7968884706497192\n",
      "Batch Error : 0.6234660744667053\n",
      "Batch Error : 0.6378499865531921\n",
      "Época 23/30, Pérdida: 0.7044568398724431\n",
      "Época 23/30\n",
      "P= 0.6158954491361263\n",
      "R= 0.6012859941486163\n",
      "F1= 0.6047821073303448\n",
      "Acc= 0.6285714285714286\n",
      "Época 24/30, Pérdida: 0.6929313929184623\n",
      "Época 24/30\n",
      "P= 0.5986297248920777\n",
      "R= 0.5829664101965023\n",
      "F1= 0.5889623199450656\n",
      "Acc= 0.6158730158730159\n",
      "Batch Error : 0.7246503233909607\n",
      "Batch Error : 0.7496144771575928\n",
      "Época 25/30, Pérdida: 0.6853394041890684\n",
      "Época 25/30\n",
      "P= 0.6393846936181032\n",
      "R= 0.5781989998566067\n",
      "F1= 0.5894742957242958\n",
      "Acc= 0.6317460317460317\n",
      "Batch Error : 0.7090910077095032\n",
      "Época 26/30, Pérdida: 0.6909609799799712\n",
      "Época 26/30\n",
      "P= 0.6169107592269653\n",
      "R= 0.6177531635944061\n",
      "F1= 0.6170641589969321\n",
      "Acc= 0.6349206349206349\n",
      "Batch Error : 0.6304877400398254\n",
      "Batch Error : 0.7188364863395691\n",
      "Batch Error : 0.5725830793380737\n",
      "Batch Error : 0.6474156975746155\n",
      "Batch Error : 0.7094764113426208\n",
      "Época 27/30, Pérdida: 0.6840205322141233\n",
      "Época 27/30\n",
      "P= 0.6167415018906285\n",
      "R= 0.5840380162786524\n",
      "F1= 0.5935920288861465\n",
      "Acc= 0.6222222222222222\n",
      "Batch Error : 0.7377024292945862\n",
      "Batch Error : 0.7162872552871704\n",
      "Época 28/30, Pérdida: 0.6767247111900992\n",
      "Época 28/30\n",
      "P= 0.6058793906584413\n",
      "R= 0.5812152734951973\n",
      "F1= 0.5892632647816612\n",
      "Acc= 0.6190476190476191\n",
      "Batch Error : 0.726050615310669\n",
      "Época 29/30, Pérdida: 0.670512652915457\n",
      "Época 29/30\n",
      "P= 0.6233658203488733\n",
      "R= 0.5823824751292795\n",
      "F1= 0.5929550170636758\n",
      "Acc= 0.6317460317460317\n",
      "Batch Error : 0.7086959481239319\n",
      "Época 30/30, Pérdida: 0.6609957321830418\n",
      "Época 30/30\n",
      "P= 0.6256469186244467\n",
      "R= 0.5924009558218192\n",
      "F1= 0.6026302266150463\n",
      "Acc= 0.6349206349206349\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "# Establecer los parámetros de la red\n",
    "\n",
    "# Parámetros de la red\n",
    "tam_entrada =  X_train.shape[1]\n",
    "\n",
    "tam_salida = 3   # 3 clases\n",
    "\n",
    "epochs = 30 # variar el número de épocas, para probar que funciona la programación \n",
    "                 # solo usar 2 épocas, para entrenamiento total usar por ejemplo 1000 épocas\n",
    "learning_rate = 0.001 # Generalmente se usan learning rate pequeños (0.001), \n",
    "\n",
    "# Se recomiendan tamaños de batch_size potencias de 2: 16, 32, 64, 128, 256\n",
    "# Entre mayor el número más cantidad de memoria se requiere para el procesamiento\n",
    "batch_size = 128 # definir el tamaño del lote de procesamiento \n",
    "\n",
    "\n",
    "# Convertir los datos de entrenamiento y etiquetas a tensores  de PyTorch\n",
    "\n",
    "X_tensor_train = torch.from_numpy(X_train)\n",
    "X_tensor_train = X_tensor_train.to(torch.float32)\n",
    "\n",
    "\n",
    "X_tensor_val = torch.from_numpy(X_val)\n",
    "X_tensor_val = X_tensor_val.to(torch.float32)\n",
    "\n",
    "\n",
    "# Crear la red\n",
    "modelo_red_neuronal = RedNeuronal(tam_entrada, tam_salida)\n",
    "\n",
    "# Definir la función de pérdida\n",
    "# Entropía Cruzada \n",
    "criterion = nn.CrossEntropyLoss() \n",
    "\n",
    "# Definir el optimizador\n",
    "# Parámetros del optimizador: parámetros del modelo y learning rate \n",
    "# Adaptive Moment Estimation\n",
    "optimizer = optim.Adam(modelo_red_neuronal.parameters(), lr=learning_rate)\n",
    "\n",
    "# Entrenamiento\n",
    "print(\"Iniciando entrenamiento en PyTorch\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "# Poner el modelo en modo de entrenamiento\n",
    "    modelo_red_neuronal.train()  \n",
    "    lossTotal = 0\n",
    "    #definir el batch_size\n",
    "    dataloader = create_minibatches(X_tensor_train, Y_train_one_hot, batch_size=batch_size)\n",
    "    for X_tr, y_tr in dataloader:\n",
    "        # inicializar los gradientes en cero para cada época\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Propagación hacia adelante\n",
    "        y_pred = modelo_red_neuronal(X_tr)  #invoca al método forward de la clase MLP\n",
    "        # Calcular el error MSE\n",
    "        loss = criterion(y_pred, y_tr)\n",
    "        #Acumular el error \n",
    "        lossTotal += loss.item()\n",
    "        \n",
    "        # Propagación hacia atrás: cálculo de los gradientes de los pesos y bias\n",
    "        loss.backward()\n",
    "        \n",
    "        # actualización de los pesos: regla de actualización basado en el gradiente:\n",
    "        #  \n",
    "        optimizer.step()\n",
    "        if np.random.random() < 0.1:\n",
    "            print(f\"Batch Error : {loss.item()}\")\n",
    "\n",
    "    print(f\"Época {epoch+1}/{epochs}, Pérdida: {lossTotal/len(dataloader)}\")\n",
    "    \n",
    "    # Evalúa el modelo con el conjunto de validación\n",
    "    modelo_red_neuronal.eval()  # Establecer el modo del modelo a \"evaluación\"\n",
    "    with torch.no_grad():  # No  calcular gradientes \n",
    "        y_pred = modelo_red_neuronal(X_tensor_val)\n",
    "        # Obtiene una única clase, la más probable\n",
    "        y_pred = torch.argmax(y_pred, dim=1)\n",
    "        print(f\"Época {epoch+1}/{epochs}\")\n",
    "        print(\"P=\", precision_score(Y_val, y_pred, average='macro'))\n",
    "        print(\"R=\", recall_score(Y_val, y_pred, average='macro'))\n",
    "        print(\"F1=\", f1_score(Y_val, y_pred, average='macro'))\n",
    "        print(\"Acc=\", accuracy_score(Y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modo para predicción de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 0, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# TODO: Transformar el dataset de test con los mismos preprocesamientos y al  espacio de \n",
    "# representación vectorial que el modelo entrenado, es decir, al espacio de la matriz TFIDF\n",
    "\n",
    "# Convertir los datos de prueba a tensores de PyTorch\n",
    "\n",
    "X_tensor_test = torch.from_numpy(X_test)\n",
    "X_tensor_test = X_tensor_test.to(torch.float32)\n",
    "\n",
    "# Desactivar el comportamiento de modo de  entrenamiento: por ejemplo, capas como Dropout\n",
    "modelo_red_neuronal.eval()  # Establecer el modo del modelo a \"evaluación\"\n",
    "\n",
    "with torch.no_grad():  # No  calcular gradientes \n",
    "    y_pred_test= modelo_red_neuronal(X_tensor_test)\n",
    "\n",
    "# y_test_pred contiene las predicciones\n",
    "\n",
    "# Obtener la clase real\n",
    "y_pred_test = torch.argmax(y_pred_test, dim=1)\n",
    "\n",
    "print(y_pred_test[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 67  70  36]\n",
      " [ 20 307  44]\n",
      " [ 21  75 146]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6204    0.3873    0.4769       173\n",
      "           1     0.6792    0.8275    0.7461       371\n",
      "           2     0.6460    0.6033    0.6239       242\n",
      "\n",
      "    accuracy                         0.6616       786\n",
      "   macro avg     0.6485    0.6060    0.6156       786\n",
      "weighted avg     0.6560    0.6616    0.6492       786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: Evaluar el modelo con las predicciones obtenidas y las etiquetas esperadas: \n",
    "# classification_report y  matriz de confusión (métricas Precisión, Recall, F1-measaure, Accuracy)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "Y_test_encoded = le.transform(Y_test)\n",
    "\n",
    "print(confusion_matrix(Y_test_encoded, y_pred_test))\n",
    "print(classification_report(Y_test_encoded, y_pred_test, digits=4, zero_division='warn'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guardar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Obtener el state_dict (diccionario de pesos y sesgos)\n",
    "state_dict = modelo_red_neuronal.state_dict()\n",
    "\n",
    "# Guardar el state_dict\n",
    "torch.save(state_dict, \"./data/red_neuronal_parametros.pth\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
