{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementar un Multilayer Perceptron  con PyTorch para clasificación de texto\n",
    "# Uso de word embeddings como representación de datos\n",
    "\n",
    "\n",
    "<img src=\"figs/fig-diagrama-clasificador2.png\" width=\"900\">\n",
    "\n",
    "\n",
    "### 1. **Representar los datos en el modelo de word embeddings seleccionado**:  \n",
    "   - #### Generalmente, solo se tokeniza para separar adecuadamente las palabras.\n",
    "   - #### Sin embargo, dependiendo del modelos de word embeddings algunos preprocesamientos puede mejorar la representación.\n",
    "   - #### Por ejemplo: \n",
    "      - ##### tokenizar y separar correctamente las oraciones y palabras\n",
    "      - ##### convertir a minúsculas\n",
    "      - ##### quitar acentos (dependiendo de la fuente de datos con la que se generaros los embeddings)\n",
    "      - ##### quitar números y puntuación \n",
    "\n",
    "\n",
    "### 3. **Convertir los datos a vectores densos: word embeddings**:  \n",
    "   - #### En el caso de textos corto a nivel de oración, un vector denso por oración. \n",
    "\n",
    "### 4. **Separar los datos para entrenamiento, validación y prueba**:  \n",
    "   - #### Crear los dataset  con la función train_test_split \n",
    "   \n",
    "### 5. **Definir la arquitectura de la red**:  \n",
    "   - Definir una red de 2 capas, con funciones PReLU en las capas ocultas y una capa de salida\n",
    "\n",
    "### 6. **Entrenar el modelo**:  \n",
    "   - Definir los parámetros de las red como: número de épocas, learning_rate, número de neuronas para las capas ocultas, etc.\n",
    "   \n",
    "### 7. **Evaluar el modelo**:  \n",
    "   - Después del entrenamiento, probar la red con las entradas del conjunto de test y evaluar el desempeño con las métricas: Precisión, Recall, F1-score o F1-Measure y Accuracy.\n",
    "   \n",
    "\n",
    "### 8. **Guardar el modelo**:  \n",
    "   - Después del entrenamiento, el modelo se guarda para posteriores usos: despliegue del modelo para aplicación web, o como punto de partida para optimizar por medio de Computación Evolutiva.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar los datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de ejemplos de entrenamiento\n",
      "klass\n",
      "neutral     1485\n",
      "positive     968\n",
      "negative     689\n",
      "Name: count, dtype: int64\n",
      "Datos train: (3142, 300)\n",
      "Etiquetas train: (3142,)\n",
      "Datos test: (786, 300)\n",
      "Etiquetas test: (786,)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import fasttext\n",
    "\n",
    "# colocar la semilla para la generación de números aleatorios para la reproducibilidad de experimentos\n",
    "\n",
    "random_state = 42\n",
    "torch.manual_seed(random_state)\n",
    "np.random.seed(random_state)\n",
    "\n",
    "#cargar los datos\n",
    "dataset_train = pd.read_json(\"./data/dataset_polaridad_es_train_embeddings.json\", lines=True)\n",
    "dataset_test = pd.read_json(\"./data/dataset_polaridad_es_test_embeddings.json\", lines=True)\n",
    "\n",
    "#conteo de clases\n",
    "print(\"Total de ejemplos de entrenamiento\")\n",
    "print(dataset_train.klass.value_counts())\n",
    "# Extracción de los vectores de embeddings que representan a los textos\n",
    "X = np.vstack(dataset_train['we_es'].to_numpy())\n",
    "# Extracción de las etiquetas o clases de entrenamiento\n",
    "Y = dataset_train['klass'].to_numpy()\n",
    "\n",
    "X_test = np.vstack(dataset_test['we_es'].to_numpy())\n",
    "# Extracción de las etiquetas o clases de entrenamiento\n",
    "Y_test = dataset_test['klass'].to_numpy()\n",
    "\n",
    "\n",
    "print(\"Datos train:\", X.shape) \n",
    "print(\"Etiquetas train:\", Y.shape) \n",
    "print(\"Datos test:\", X_test.shape) \n",
    "print(\"Etiquetas test:\", Y_test.shape) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codificar las etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases:\n",
      "['negative' 'neutral' 'positive']\n",
      "Clases codificadas:\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Codificar las etiquetas de los datos a una forma categórica numérica: LabelEncoder.\n",
    "\n",
    "le = LabelEncoder()\n",
    "# Normalizar las etiquetas a una codificación ordinal para entrada del clasificador\n",
    "Y_encoded= le.fit_transform(Y)\n",
    "print(\"Clases:\")\n",
    "print(le.classes_)\n",
    "print(\"Clases codificadas:\")\n",
    "print(le.transform(le.classes_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparar los conjuntos de datos  para el entrenamiento, validación y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dividir el conjunto de entrenamiento en:  entrenamiento (80%) y validación (10%)\n",
    "X_train, X_val, Y_train, Y_val =  train_test_split(X, Y_encoded, test_size=0.1, stratify=Y_encoded, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Codificar las clases en forma one-hot \n",
    "NUM_CLASSES = 3\n",
    "Y_train_one_hot = nn.functional.one_hot(torch.from_numpy(Y_train), num_classes=NUM_CLASSES).float()\n",
    "\n",
    "\n",
    "# Crear minibatches en PyTorch usando DataLoader\n",
    "def create_minibatches(X, Y, batch_size):\n",
    "    # Recibe los documentos en X y las etiquetas en Y\n",
    "    dataset = TensorDataset(X, Y) # Cargar los datos en un dataset de tensores\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    # loader = DataLoader(dataset, batch_size=batch_size)\n",
    "    return loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2827, 300), (2827,), (315, 300), (315,), (786, 300), (786,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, Y_train.shape, X_val.shape, Y_val.shape, X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 1., 0.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 0., 1.]]),\n",
       " torch.Size([2827, 3]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_one_hot[:5],  Y_train_one_hot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición de la arquitectura de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Definir la red neuronal en PyTorch heredando de la clase base de Redes Neuronales: Module\n",
    "class RedNeuronal(nn.Module):\n",
    "    def __init__(self, tam_entrada, tam_salida):\n",
    "        super().__init__()\n",
    "        # Definición de capas, funciones de activación e inicialización de pesos\n",
    "        tam_entrada_capa_oculta_1 = 128\n",
    "        tam_entrada_capa_oculta_2 = 8 \n",
    "        self.fc1 = nn.Linear(tam_entrada, tam_entrada_capa_oculta_1)\n",
    "        self.fc2 = nn.Linear(tam_entrada_capa_oculta_1, tam_entrada_capa_oculta_2)\n",
    "        self.salida = nn.Linear(tam_entrada_capa_oculta_2, tam_salida)\n",
    "        self.activacion= nn.PReLU()\n",
    "\n",
    "        nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        nn.init.xavier_uniform_(self.fc2.weight)\n",
    "        nn.init.xavier_uniform_(self.salida.weight)\n",
    "\n",
    "        if self.fc1.bias is not None:\n",
    "            nn.init.zeros_(self.fc1.bias)\n",
    "        if self.fc2.bias is not None:\n",
    "            nn.init.zeros_(self.fc2.bias)        \n",
    "        if self.salida.bias is not None:\n",
    "            nn.init.zeros_(self.salida.bias)        \n",
    "\n",
    "    \n",
    "    def forward(self, X):\n",
    "        # Definición del orden de conexión de las capas y aplición de las funciones de activación\n",
    "        x = self.fc1(X)\n",
    "        x = self.activacion(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.activacion(x)\n",
    "        x = self.salida(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando entrenamiento en PyTorch\n",
      "Batch Error : 1.0693750381469727\n",
      "Batch Error : 1.0727605819702148\n",
      "Época 1/30, Pérdida: 1.0640511512756348\n",
      "Época 1/30\n",
      "P= 0.15767195767195766\n",
      "R= 0.3333333333333333\n",
      "F1= 0.21408045977011494\n",
      "Acc= 0.473015873015873\n",
      "Batch Error : 1.0078034400939941\n",
      "Época 2/30, Pérdida: 1.029496527236441\n",
      "Época 2/30\n",
      "P= 0.4394939493949395\n",
      "R= 0.36322332157106946\n",
      "F1= 0.27797623880273875\n",
      "Acc= 0.4984126984126984\n",
      "Época 3/30, Pérdida: 0.9963932762975278\n",
      "Época 3/30\n",
      "P= 0.44830508474576275\n",
      "R= 0.3850411679236145\n",
      "F1= 0.3160853160853161\n",
      "Acc= 0.5174603174603175\n",
      "Batch Error : 0.9965870380401611\n",
      "Época 4/30, Pérdida: 0.9464147116826929\n",
      "Época 4/30\n",
      "P= 0.41694537346711263\n",
      "R= 0.41285546253373\n",
      "F1= 0.36176470588235293\n",
      "Acc= 0.5365079365079365\n",
      "Batch Error : 0.9010958671569824\n",
      "Época 5/30, Pérdida: 0.9259017990983051\n",
      "Época 5/30\n",
      "P= 0.4058333333333333\n",
      "R= 0.46384833598560854\n",
      "F1= 0.4187541101213607\n",
      "Acc= 0.5714285714285714\n",
      "Batch Error : 0.8826020956039429\n",
      "Batch Error : 0.9293391108512878\n",
      "Época 6/30, Pérdida: 0.895358233348183\n",
      "Época 6/30\n",
      "P= 0.4096738047808765\n",
      "R= 0.44994118868055083\n",
      "F1= 0.4063354037267081\n",
      "Acc= 0.5619047619047619\n",
      "Batch Error : 0.8873833417892456\n",
      "Batch Error : 0.8749691843986511\n",
      "Batch Error : 0.842207670211792\n",
      "Época 7/30, Pérdida: 0.878468218057052\n",
      "Época 7/30\n",
      "P= 0.4158093278463649\n",
      "R= 0.46832260891625727\n",
      "F1= 0.42397254759892117\n",
      "Acc= 0.5777777777777777\n",
      "Batch Error : 0.8094814419746399\n",
      "Batch Error : 0.8743873834609985\n",
      "Época 8/30, Pérdida: 0.8604865799779478\n",
      "Época 8/30\n",
      "P= 0.571699223779568\n",
      "R= 0.4897203027905545\n",
      "F1= 0.47212165610675855\n",
      "Acc= 0.580952380952381\n",
      "Batch Error : 0.8759718537330627\n",
      "Batch Error : 0.8217772245407104\n",
      "Batch Error : 0.7963792085647583\n",
      "Batch Error : 0.7649186849594116\n",
      "Época 9/30, Pérdida: 0.8357433132503344\n",
      "Época 9/30\n",
      "P= 0.5954420756657458\n",
      "R= 0.5305372637143685\n",
      "F1= 0.5237639553429027\n",
      "Acc= 0.6031746031746031\n",
      "Batch Error : 0.8370319604873657\n",
      "Batch Error : 0.8082081079483032\n",
      "Batch Error : 0.75279301404953\n",
      "Época 10/30, Pérdida: 0.8260409002718718\n",
      "Época 10/30\n",
      "P= 0.6213655677503562\n",
      "R= 0.5667522681381696\n",
      "F1= 0.5703030303030303\n",
      "Acc= 0.6253968253968254\n",
      "Batch Error : 0.8471082448959351\n",
      "Batch Error : 0.7506654262542725\n",
      "Época 11/30, Pérdida: 0.8058521592098734\n",
      "Época 11/30\n",
      "P= 0.611485108119135\n",
      "R= 0.5891259725426846\n",
      "F1= 0.5969100269697788\n",
      "Acc= 0.6285714285714286\n",
      "Batch Error : 0.8117876648902893\n",
      "Batch Error : 0.7296230792999268\n",
      "Batch Error : 0.8306711912155151\n",
      "Época 12/30, Pérdida: 0.8009837243867957\n",
      "Época 12/30\n",
      "P= 0.63205199845856\n",
      "R= 0.5814402238674016\n",
      "F1= 0.590035739617533\n",
      "Acc= 0.6349206349206349\n",
      "Batch Error : 0.7477566599845886\n",
      "Batch Error : 0.7539732456207275\n",
      "Batch Error : 0.7362186908721924\n",
      "Época 13/30, Pérdida: 0.7830696857493856\n",
      "Época 13/30\n",
      "P= 0.6197278911564627\n",
      "R= 0.568313884986518\n",
      "F1= 0.5799079316189532\n",
      "Acc= 0.6253968253968254\n",
      "Batch Error : 0.8361915349960327\n",
      "Época 14/30, Pérdida: 0.7698187232017517\n",
      "Época 14/30\n",
      "P= 0.6175995179921882\n",
      "R= 0.5663337869108297\n",
      "F1= 0.5765843850845624\n",
      "Acc= 0.6253968253968254\n",
      "Batch Error : 0.7623372673988342\n",
      "Batch Error : 0.7345560193061829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/opt/miniconda3/envs/CE/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/admin/opt/miniconda3/envs/CE/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/admin/opt/miniconda3/envs/CE/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/admin/opt/miniconda3/envs/CE/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/admin/opt/miniconda3/envs/CE/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/admin/opt/miniconda3/envs/CE/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/admin/opt/miniconda3/envs/CE/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Error : 0.7828763723373413\n",
      "Batch Error : 1.1228022575378418\n",
      "Época 15/30, Pérdida: 0.7720405744469684\n",
      "Época 15/30\n",
      "P= 0.6148519061318279\n",
      "R= 0.5787508469063977\n",
      "F1= 0.5880550949155289\n",
      "Acc= 0.6285714285714286\n",
      "Batch Error : 0.7323153018951416\n",
      "Batch Error : 0.7100321054458618\n",
      "Batch Error : 0.6632977724075317\n",
      "Época 16/30, Pérdida: 0.7510512315708658\n",
      "Época 16/30\n",
      "P= 0.6107541382410493\n",
      "R= 0.5556341043482271\n",
      "F1= 0.5645468998410176\n",
      "Acc= 0.6158730158730159\n",
      "Batch Error : 0.7486873269081116\n",
      "Batch Error : 0.8050156235694885\n",
      "Época 17/30, Pérdida: 0.7393786725790604\n",
      "Época 17/30\n",
      "P= 0.6466487497556122\n",
      "R= 0.5523270330516606\n",
      "F1= 0.560933238583887\n",
      "Acc= 0.6222222222222222\n",
      "Batch Error : 0.804322361946106\n",
      "Batch Error : 0.7041562795639038\n",
      "Época 18/30, Pérdida: 0.7265563762706259\n",
      "Época 18/30\n",
      "P= 0.6309758339900184\n",
      "R= 0.5690231638718338\n",
      "F1= 0.5761512890345387\n",
      "Acc= 0.6317460317460317\n",
      "Batch Error : 0.7128019332885742\n",
      "Batch Error : 0.5991825461387634\n",
      "Época 19/30, Pérdida: 0.7236901132956796\n",
      "Época 19/30\n",
      "P= 0.598257169708048\n",
      "R= 0.5725912845602154\n",
      "F1= 0.5806758885281099\n",
      "Acc= 0.6158730158730159\n",
      "Batch Error : 0.763727068901062\n",
      "Batch Error : 0.6813163161277771\n",
      "Época 20/30, Pérdida: 0.7191632778748221\n",
      "Época 20/30\n",
      "P= 0.6095987724482836\n",
      "R= 0.5901300600881552\n",
      "F1= 0.5964116620533847\n",
      "Acc= 0.6285714285714286\n",
      "Batch Error : 0.759698748588562\n",
      "Batch Error : 0.6455332040786743\n",
      "Época 21/30, Pérdida: 0.7093556912049003\n",
      "Época 21/30\n",
      "P= 0.6058127647144734\n",
      "R= 0.5900344645362229\n",
      "F1= 0.5956527774503871\n",
      "Acc= 0.6222222222222222\n",
      "Batch Error : 0.6961989998817444\n",
      "Batch Error : 0.6681599617004395\n",
      "Batch Error : 0.8202940225601196\n",
      "Época 22/30, Pérdida: 0.728577126627383\n",
      "Época 22/30\n",
      "P= 0.6143306768306768\n",
      "R= 0.596612508109745\n",
      "F1= 0.5992643968053805\n",
      "Acc= 0.6349206349206349\n",
      "Batch Error : 0.743833601474762\n",
      "Batch Error : 0.7346788048744202\n",
      "Batch Error : 0.7721819877624512\n",
      "Época 23/30, Pérdida: 0.7133516410122747\n",
      "Época 23/30\n",
      "P= 0.6122228648544438\n",
      "R= 0.5632202464693989\n",
      "F1= 0.5722842216386983\n",
      "Acc= 0.6158730158730159\n",
      "Batch Error : 0.7225462794303894\n",
      "Época 24/30, Pérdida: 0.698336150335229\n",
      "Época 24/30\n",
      "P= 0.6065651999196303\n",
      "R= 0.5902296666422665\n",
      "F1= 0.5954400843731705\n",
      "Acc= 0.6222222222222222\n",
      "Batch Error : 0.8121658563613892\n",
      "Batch Error : 0.6061966419219971\n",
      "Batch Error : 0.7391242384910583\n",
      "Época 25/30, Pérdida: 0.7168777481369351\n",
      "Época 25/30\n",
      "P= 0.6034065504135926\n",
      "R= 0.5952220273543664\n",
      "F1= 0.5979396496748853\n",
      "Acc= 0.6222222222222222\n",
      "Batch Error : 0.7090810537338257\n",
      "Batch Error : 0.5286690592765808\n",
      "Batch Error : 0.6777728199958801\n",
      "Batch Error : 0.7514787912368774\n",
      "Época 26/30, Pérdida: 0.7168616548828457\n",
      "Época 26/30\n",
      "P= 0.631456853413021\n",
      "R= 0.6012482238780976\n",
      "F1= 0.6054875828738204\n",
      "Acc= 0.638095238095238\n",
      "Batch Error : 0.6589116454124451\n",
      "Batch Error : 0.6072362065315247\n",
      "Batch Error : 0.6707844138145447\n",
      "Batch Error : 0.7274399995803833\n",
      "Batch Error : 0.30637410283088684\n",
      "Época 27/30, Pérdida: 0.675701212623845\n",
      "Época 27/30\n",
      "P= 0.6134566822066821\n",
      "R= 0.5504465415300837\n",
      "F1= 0.5578344980946869\n",
      "Acc= 0.6158730158730159\n",
      "Batch Error : 0.7444005608558655\n",
      "Batch Error : 0.6646647453308105\n",
      "Época 28/30, Pérdida: 0.6858917228553606\n",
      "Época 28/30\n",
      "P= 0.6283153387240027\n",
      "R= 0.5953794591898912\n",
      "F1= 0.598608895977317\n",
      "Acc= 0.6317460317460317\n",
      "Batch Error : 0.7593414783477783\n",
      "Batch Error : 0.7462513446807861\n",
      "Batch Error : 0.5684290528297424\n",
      "Época 29/30, Pérdida: 0.7075894086257272\n",
      "Época 29/30\n",
      "P= 0.6082691021715413\n",
      "R= 0.5957080271183858\n",
      "F1= 0.6006303428028668\n",
      "Acc= 0.6285714285714286\n",
      "Época 30/30, Pérdida: 0.684702798076298\n",
      "Época 30/30\n",
      "P= 0.623628523161732\n",
      "R= 0.6094537315857397\n",
      "F1= 0.6150888302051093\n",
      "Acc= 0.6412698412698413\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "# Establecer los parámetros de la red\n",
    "\n",
    "# Parámetros de la red\n",
    "tam_entrada =  X_train.shape[1]\n",
    "\n",
    "tam_salida = 3   # 2 clases\n",
    "\n",
    "epochs = 30 # variar el número de épocas, para probar que funciona la programación \n",
    "                 # solo usar 2 épocas, para entrenamiento total usar por ejemplo 1000 épocas\n",
    "learning_rate = 0.001 # Generalmente se usan learning rate pequeños (0.001), \n",
    "\n",
    "# Se recomiendan tamaños de batch_size potencias de 2: 16, 32, 64, 128, 256\n",
    "# Entre mayor el número más cantidad de memoria se requiere para el procesamiento\n",
    "batch_size = 128 # definir el tamaño del lote de procesamiento \n",
    "\n",
    "\n",
    "# Convertir los datos de entrenamiento y etiquetas a tensores  de PyTorch\n",
    "\n",
    "X_train_t = torch.from_numpy(X_train)\n",
    "X_train_t = X_train_t.to(torch.float32)\n",
    "Y_train_t = Y_train_one_hot\n",
    "\n",
    "X_val_t = torch.from_numpy(X_val)\n",
    "X_val_t = X_val_t.to(torch.float32)\n",
    "\n",
    "\n",
    "# Crear la red\n",
    "modelo_red_neuronal = RedNeuronal(tam_entrada, tam_salida)\n",
    "\n",
    "# Definir la función de pérdida\n",
    "# Entropía Cruzada \n",
    "criterion = nn.CrossEntropyLoss() \n",
    "\n",
    "# Definir el optimizador\n",
    "#Parámetros del optimizador: parámetros del modelo y learning rate \n",
    "# Adaptive Moment Estimation\n",
    "optimizer = optim.Adam(modelo_red_neuronal.parameters(), lr=learning_rate)\n",
    "\n",
    "# Entrenamiento\n",
    "print(\"Iniciando entrenamiento en PyTorch\")\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "# Poner el modelo en modo de entrenamiento\n",
    "    modelo_red_neuronal.train()  \n",
    "    lossTotal = 0\n",
    "    #definir el batch_size\n",
    "    dataloader = create_minibatches(X_train_t, Y_train_t, batch_size=batch_size)\n",
    "    for X_tr, y_tr in dataloader:\n",
    "        # inicializar los gradientes en cero para cada época\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Propagación hacia adelante\n",
    "        y_pred = modelo_red_neuronal(X_tr)  #invoca al método forward de la clase MLP\n",
    "        # Calcular el error MSE\n",
    "        loss = criterion(y_pred, y_tr)\n",
    "        #Acumular el error \n",
    "        lossTotal += loss.item()\n",
    "        \n",
    "        # Propagación hacia atrás: cálculo de los gradientes de los pesos y bias\n",
    "        loss.backward()\n",
    "        \n",
    "        # actualización de los pesos: regla de actualización basado en el gradiente:\n",
    "        #  \n",
    "        optimizer.step()\n",
    "        if np.random.random() < 0.1:\n",
    "            print(f\"Batch Error : {loss.item()}\")\n",
    "\n",
    "    print(f\"Época {epoch+1}/{epochs}, Pérdida: {lossTotal/len(dataloader)}\")\n",
    "    \n",
    "    # Evalúa el modelo con el conjunto de validación\n",
    "    modelo_red_neuronal.eval()  # Establecer el modo del modelo a \"evaluación\"\n",
    "    with torch.no_grad():  # No  calcular gradientes \n",
    "        y_pred = modelo_red_neuronal(X_val_t)\n",
    "        # Obtiene una única clase, la más probable\n",
    "        y_pred = torch.argmax(y_pred, dim=1)\n",
    "        print(f\"Época {epoch+1}/{epochs}\")\n",
    "        print(\"P=\", precision_score(Y_val, y_pred, average='macro'))\n",
    "        print(\"R=\", recall_score(Y_val, y_pred, average='macro'))\n",
    "        print(\"F1=\", f1_score(Y_val, y_pred, average='macro'))\n",
    "        print(\"Acc=\", accuracy_score(Y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modo para predicción de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 0, 1, 1, 1, 2, 2, 1, 0, 1, 2, 2, 2, 1, 1, 1, 1, 1, 2, 0, 1, 2, 1,\n",
      "        1, 0, 2, 1, 0, 1, 1, 1, 2, 1, 1, 0, 1, 1, 1, 2, 0, 1, 2, 2, 1, 1, 2, 1,\n",
      "        1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 0, 1, 2, 1, 2, 1, 0, 1, 1, 2, 0, 1,\n",
      "        2, 1, 1, 1, 1, 2, 2, 0, 1, 2, 0, 1, 1, 1, 0, 2, 1, 1, 2, 0, 1, 1, 2, 1,\n",
      "        1, 1, 1, 1, 0, 1, 1, 2, 1, 0, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2,\n",
      "        2, 1, 1, 0, 0, 1, 0, 1, 2, 1, 1, 1, 2, 2, 2, 1, 1, 2, 2, 2, 1, 1, 2, 2,\n",
      "        2, 2, 1, 1, 0, 2, 0, 0, 1, 1, 2, 0, 2, 0, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1,\n",
      "        1, 2, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 0, 2, 1, 0, 1, 1, 0, 2, 2, 1,\n",
      "        2, 2, 1, 1, 1, 2, 1, 2, 1, 0, 1, 1, 0, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 1, 0, 0, 1, 2, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 2, 1, 1, 1, 2, 2, 1,\n",
      "        1, 2, 1, 2, 1, 0, 1, 1, 2, 1, 0, 1, 1, 2, 0, 1, 1, 2, 2, 2, 2, 2, 2, 0,\n",
      "        1, 0, 1, 1, 0, 1, 2, 1, 2, 2, 1, 1, 2, 1, 1, 1, 2, 2, 1, 0, 2, 0, 2, 2,\n",
      "        1, 0, 2, 1, 2, 1, 1, 1, 0, 1, 2, 0, 1, 0, 2, 2, 0, 2, 1, 1, 1, 0, 2, 2,\n",
      "        2, 1, 1, 1, 1, 0, 2, 0, 1, 1, 1, 1, 1, 0, 1, 2, 0, 1, 2, 2, 1, 1, 1, 1,\n",
      "        0, 1, 1, 0, 1, 2, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 2, 2, 0, 1, 1, 1,\n",
      "        2, 1, 1, 1, 0, 0, 2, 2, 1, 0, 2, 1, 2, 0, 0, 0, 2, 2, 2, 1, 0, 1, 1, 1,\n",
      "        2, 1, 2, 2, 1, 2, 0, 1, 1, 2, 1, 0, 1, 1, 2, 2, 0, 1, 1, 1, 2, 1, 2, 0,\n",
      "        2, 1, 2, 1, 0, 2, 1, 1, 2, 1, 2, 2, 1, 1, 2, 0, 0, 0, 1, 1, 2, 0, 1, 1,\n",
      "        2, 2, 2, 0, 1, 1, 1, 2, 0, 1, 2, 0, 1, 1, 1, 2, 1, 0, 0, 2, 0, 1, 2, 1,\n",
      "        1, 2, 2, 2, 2, 0, 1, 1, 2, 2, 0, 2, 1, 1, 0, 2, 1, 2, 2, 0, 0, 2, 1, 1,\n",
      "        1, 2, 1, 1, 0, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 0, 2, 1, 1, 2, 1, 1,\n",
      "        1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 2, 0, 1, 2, 0, 1, 1, 1, 1, 2, 1, 1,\n",
      "        2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 2, 1, 1, 0, 1, 1, 1, 2, 1,\n",
      "        0, 1, 2, 1, 0, 1, 2, 1, 1, 1, 2, 1, 2, 1, 2, 0, 1, 1, 2, 0, 1, 1, 0, 1,\n",
      "        1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 0, 2, 2, 1, 1, 0, 2, 0, 2, 2,\n",
      "        0, 2, 1, 0, 2, 2, 1, 1, 0, 2, 1, 0, 1, 2, 0, 1, 2, 2, 1, 2, 2, 2, 2, 1,\n",
      "        1, 0, 1, 0, 2, 2, 2, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 0, 1,\n",
      "        1, 0, 0, 1, 0, 1, 1, 2, 2, 1, 1, 1, 0, 1, 1, 1, 0, 2, 0, 2, 1, 1, 1, 2,\n",
      "        1, 1, 2, 1, 2, 0, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 0, 0, 2, 1, 1,\n",
      "        0, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 1, 2, 1, 1, 0, 0, 1, 2,\n",
      "        1, 2, 2, 1, 2, 2, 2, 1, 0, 1, 1, 1, 2, 2, 0, 1, 1, 0, 2, 1, 2, 1, 1, 1,\n",
      "        2, 0, 1, 1, 1, 1, 1, 1, 2, 0, 1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 0, 1, 1, 0,\n",
      "        0, 0, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 0, 2, 2, 0, 2, 0])\n"
     ]
    }
   ],
   "source": [
    "# TODO: Transformar el dataset de test con los mismos preprocesamientos y al  espacio de \n",
    "# representación vectorial que el modelo entrenado, es decir, al espacio de la matriz TFIDF\n",
    "\n",
    "# Convertir los datos de prueba a tensores de PyTorch\n",
    "\n",
    "X_t = torch.from_numpy(X_test)\n",
    "X_t = X_t.to(torch.float32)\n",
    "\n",
    "# Desactivar el comportamiento de modo de  entrenamiento: por ejemplo, capas como Dropout\n",
    "modelo_red_neuronal.eval()  # Establecer el modo del modelo a \"evaluación\"\n",
    "\n",
    "with torch.no_grad():  # No  calcular gradientes \n",
    "    y_pred_test= modelo_red_neuronal(X_t)\n",
    "\n",
    "# y_test_pred contiene las predicciones\n",
    "\n",
    "# Obtener la clase real\n",
    "y_pred_test = torch.argmax(y_pred_test, dim=1)\n",
    "\n",
    "print(y_pred_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 75  60  38]\n",
      " [ 34 287  50]\n",
      " [ 27  72 143]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5515    0.4335    0.4854       173\n",
      "           1     0.6850    0.7736    0.7266       371\n",
      "           2     0.6190    0.5909    0.6047       242\n",
      "\n",
      "    accuracy                         0.6425       786\n",
      "   macro avg     0.6185    0.5993    0.6056       786\n",
      "weighted avg     0.6353    0.6425    0.6360       786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: Evaluar el modelo con las predicciones obtenidas y las etiquetas esperadas: \n",
    "# classification_report y  matriz de confusión (métricas Precisión, Recall, F1-measaure, Accuracy)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "Y_t = le.transform(Y_test)\n",
    "\n",
    "print(confusion_matrix(Y_t, y_pred_test))\n",
    "print(classification_report(Y_t, y_pred_test, digits=4, zero_division='warn'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guardar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Obtener el state_dict (diccionario de pesos y sesgos)\n",
    "state_dict = modelo_red_neuronal.state_dict()\n",
    "\n",
    "# Guardar el state_dict\n",
    "torch.save(state_dict, \"./data/red_neuronal_parametros.pth\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
