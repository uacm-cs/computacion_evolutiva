{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuroevolución de modelos preentrenados y Word Embeddings\n",
    "- ### La neuroevolución es una técnica de inteligencia artificial que combina redes neuronales con algoritmos evolutivos.\n",
    "- ### Optimiza automáticamente la estructura y parámetros de una red."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representación del texto: Word Embeddings\n",
    "\n",
    "- ### **Word embeddings** son representaciones numéricas densas y continuas de palabras en un espacio vectorial.\n",
    "- ### Estas representaciones capturan relaciones semánticas y sintácticas entre palabras.\n",
    "- ### Palabras con significados similares están más cercanas en el espacio vectorial.\n",
    "- ### Densidad: Cada palabra u oración se representa como un vector en un espacio de dimensiones reducidas (por ejemplo, 100 o 300 dimensiones)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar los datos representados como word embeddings para el clasificador "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de ejemplos de entrenamiento\n",
      "klass\n",
      "neutral     1485\n",
      "positive     968\n",
      "negative     689\n",
      "Name: count, dtype: int64\n",
      "Datos train: torch.Size([3142, 300])\n",
      "Etiquetas train: (3142,)\n",
      "Datos test: (786, 300)\n",
      "Etiquetas test: (786,)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.corpus import stopwords\n",
    "import random\n",
    "# colocar la semilla para la generación de números aleatorios para la reproducibilidad de experimentos\n",
    "\n",
    "\n",
    "random_state = 42\n",
    "torch.manual_seed(random_state)\n",
    "np.random.seed(random_state)\n",
    "random.seed(random_state)\n",
    "\n",
    "#cargar los datos\n",
    "dataset_train = pd.read_json(\"./data/dataset_polaridad_es_train_embeddings.json\", lines=True)\n",
    "dataset_test = pd.read_json(\"./data/dataset_polaridad_es_test_embeddings.json\", lines=True)\n",
    "\n",
    "#conteo de clases\n",
    "print(\"Total de ejemplos de entrenamiento\")\n",
    "print(dataset_train.klass.value_counts())\n",
    "# Extracción de los vectores de embeddings que representan a los textos: Embeddings de España 'we_es'\n",
    "X_tensor_train = torch.tensor(np.vstack(dataset_train['we_es'].to_numpy()))\n",
    "X_tensor_train = X_tensor_train.to(torch.float32)\n",
    "# Extracción de las etiquetas o clases de entrenamiento\n",
    "Y_train = dataset_train['klass'].to_numpy()\n",
    "\n",
    "X_test = np.vstack(dataset_test['we_es'].to_numpy())\n",
    "# Extracción de las etiquetas o clases de entrenamiento\n",
    "Y_test = dataset_test['klass'].to_numpy()\n",
    "\n",
    "\n",
    "print(\"Datos train:\", X_tensor_train.shape) \n",
    "print(\"Etiquetas train:\", Y_train.shape) \n",
    "print(\"Datos test:\", X_test.shape) \n",
    "print(\"Etiquetas test:\", Y_test.shape) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codificar las etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases:\n",
      "['negative' 'neutral' 'positive']\n",
      "Clases codificadas:\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Codificar las etiquetas de los datos a una forma categórica numérica: LabelEncoder.\n",
    "\n",
    "le = LabelEncoder()\n",
    "# Normalizar las etiquetas a una codificación ordinal para entrada del clasificador\n",
    "Y_train_encoded= le.fit_transform(Y_train)\n",
    "print(\"Clases:\")\n",
    "print(le.classes_)\n",
    "print(\"Clases codificadas:\")\n",
    "print(le.transform(le.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 1, ..., 0, 1, 1], shape=(3142,))"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de la arquitectura de la red para cargar el modelo preentrenado\n",
    "- ### Nota. El modelo de la red debe ser identico al modelo con el que se generaron los pesos y bias en el archivo exportado "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Definir la red neuronal en PyTorch heredando de la clase base de Redes Neuronales: Module\n",
    "class RedNeuronal(nn.Module):\n",
    "    def __init__(self, tam_entrada, tam_salida):\n",
    "        super().__init__()\n",
    "        # Definición de capas, funciones de activación e inicialización de pesos\n",
    "        tam_entrada_capa_oculta_1 = 128\n",
    "        tam_entrada_capa_oculta_2 = 8 \n",
    "        self.fc1 = nn.Linear(tam_entrada, tam_entrada_capa_oculta_1)\n",
    "        self.fc2 = nn.Linear(tam_entrada_capa_oculta_1, tam_entrada_capa_oculta_2)\n",
    "        self.salida = nn.Linear(tam_entrada_capa_oculta_2, tam_salida)\n",
    "        self.activacion= nn.PReLU()\n",
    "\n",
    "        nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        nn.init.xavier_uniform_(self.fc2.weight)\n",
    "        nn.init.xavier_uniform_(self.salida.weight)\n",
    "\n",
    "        if self.fc1.bias is not None:\n",
    "            nn.init.zeros_(self.fc1.bias)\n",
    "        if self.fc2.bias is not None:\n",
    "            nn.init.zeros_(self.fc2.bias)        \n",
    "        if self.salida.bias is not None:\n",
    "            nn.init.zeros_(self.salida.bias)        \n",
    "\n",
    "    \n",
    "    def forward(self, X):\n",
    "        # Definición del orden de conexión de las capas y aplición de las funciones de activación\n",
    "        x = self.fc1(X)\n",
    "        x = self.activacion(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.activacion(x)\n",
    "        x = self.salida(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar el modelo preentrenado de la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Cargar el modelo de la red neuronal desde el diccionario de pesos y sesgos\n",
    "# Parámetros de la red\n",
    "tam_entrada =  X_tensor_train.shape[1]\n",
    "tam_salida = 3   # 3 clases\n",
    "\n",
    "modelo_red_neuronal = RedNeuronal(tam_entrada, tam_salida)\n",
    "# Se carga el modelo preentrenado\n",
    "state_dict = torch.load(\"./data/red_neuronal_parametros.pth\")\n",
    "# Se cargan los pesos y bias al modelo de la red definida\n",
    "modelo_red_neuronal.load_state_dict(state_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predecir datos del test con el modelo preentrenado de la red neuronal\n",
    "- ### Con el objetivo de probar que funciona correctamente la red para predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score en test set: 0.6156\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "Y_test_encoded = le.transform(Y_test)\n",
    "\n",
    "X_tensor_test = torch.tensor(X_test)\n",
    "X_tensor_test = X_tensor_test.to(torch.float32)\n",
    "\n",
    "# Desactivar el comportamiento de modo de  entrenamiento: por ejemplo, capas como Dropout\n",
    "modelo_red_neuronal.eval()  # Establecer el modo del modelo a \"evaluación\"\n",
    "\n",
    "with torch.no_grad():  # No  calcular gradientes \n",
    "    # Ejecuta el modelo: forward pass\n",
    "    y_pred_test= modelo_red_neuronal(X_tensor_test)\n",
    "    # Calcula la clase predica que contiene el mayor valor de la predicción\n",
    "    y_pred_test = torch.argmax(y_pred_test, dim=1)\n",
    "    # Calcula la métrica F1\n",
    "    score = f1_score(Y_test_encoded, y_pred_test, average=\"macro\")\n",
    "    print(f\"F1-score en test set: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmo Genético\n",
    "## Objetivo General:\n",
    "- ### Evolucionar diferentes variantes de la red neuronal preentrenada (individuos) para encontrar al mejor individuo, esto es, el mejor modelo de red neuronal que maximice el rendimiento al predecir datos.\n",
    "\n",
    "\n",
    "## Objetivos Particulares:\n",
    "- ### 1. Generar una población de individuos que representan a la red red neuronal preentrenada con ligeras variaciones para dar diversidad de la población\n",
    "- ### 2. Representar a los individuos como versiones diferentes de la red neuronal preentrenada.\n",
    "- ### 3. Por medio de los operadores de variación (cruza y mutación),  evolucionar a los individuos (modelos de red neuronal) para mejorar el rendimiento al predecir nuevos datos. La evolución se realiza al cruzar y mutar los parámetros de los individuos (versiones diferentes del modelo de la red neuronal preentrenada) pesos y bias para ajustarlos mejor para la predicción de datos nuevos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from multiprocessing import  cpu_count\n",
    "from sklearn.metrics import f1_score\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "#------------------------------------------------------------------------\n",
    "# Funciones del algoritmo genético\n",
    "#------------------------------------------------------------------------\n",
    "#------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "_TAM_ENTRADA = X_tensor_train.shape[1]\n",
    "_TAM_SALIDA = 3 # 3 clases\n",
    "\n",
    "def copiar_red_neuronal(red_neuronal, prob_global=0.8, prob_alterar=0.5, intensidad_ruido=0.01, excluir_bias=True):\n",
    "    \"\"\"\n",
    "    Genera variantes del modelo preentrenado \"red_neuronal\" de manera aleatoria y con una constante de intensidad del ruido \n",
    "    para controlar el ruido por añadir a los parámetros\n",
    "\n",
    "    red_neuronal: modelo de la red neuronal preentrenada\n",
    "    prob_global: indica la probabilidad mínima para realizar una versión modificada de la red neuronal preentrenada\n",
    "    prob_alterar: indica la probabilidad de modificar el parámetro (pesos y/o bias)\n",
    "    intensidad_ruido: constante que modifica la intensidad de ruido que se agrega a los pesos y/o bias para generar una variante de la red neuronal preentrenada\n",
    "    excluir_bias: indica si se altera el bias o no.\n",
    "\n",
    "    \"\"\"\n",
    "    red_destino = RedNeuronal(_TAM_ENTRADA, _TAM_SALIDA)\n",
    "    red_destino.load_state_dict(red_neuronal.state_dict())\n",
    "\n",
    "    if random.random() < prob_global:\n",
    "        # No hacer cambios, devolver copia exacta\n",
    "        return red_destino\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for name, param in red_destino.named_parameters():\n",
    "            # Saltar bias si está configurado\n",
    "            if excluir_bias and 'bias' in name:\n",
    "                continue\n",
    "                \n",
    "            # Decidir si alteramos este parámetro específico \n",
    "            if random.random() < prob_alterar:\n",
    "                # Devuelve un tensor con el mismo tamaño que la entrada con números aleatorios \n",
    "                # de una distribución normal con media 0 y varianza 1.\n",
    "                ruido = torch.randn_like(param) * intensidad_ruido\n",
    "                param.add_(ruido)        \n",
    "    return red_destino\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "def inicializar_poblacion(red_neuronal, tam_poblacion):\n",
    "    \"\"\"\n",
    "    Crea la población con versiones modificadas de la red neuronal preentrenada\n",
    "    \"\"\"\n",
    "    poblacion = []\n",
    "    for _ in range(tam_poblacion):\n",
    "        poblacion.append(copiar_red_neuronal(red_neuronal))\n",
    "    return poblacion\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "def funcion_fitness(red_neuronal, X, Y):\n",
    "    \n",
    "    \"\"\"Calcula el F1-score de la red neuronal en el conjunto de datos X. Y indica la clase que se predice\"\"\"\n",
    "    # Colocar la red neuronal en modo de evaluación\n",
    "    red_neuronal.eval()\n",
    "    with torch.no_grad():\n",
    "        # Ejecuta el modelo: forward pass\n",
    "        y_pred = red_neuronal(X)\n",
    "        # Calcula la clase predica que contiene el mayor valor de la predicción\n",
    "        y_pred = torch.argmax(y_pred, axis=1)\n",
    "        # Calcula la métrica F1\n",
    "        return f1_score(Y, y_pred, average=\"macro\")  # Usar F1 macro\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "def evaluar_poblacion(poblacion, X, Y):\n",
    "    \"\"\"\n",
    "    Evalua a todos los individuos de la población\n",
    "    \"\"\"\n",
    "    fitness = []\n",
    "    for individuo in poblacion:\n",
    "        val_fitness = funcion_fitness(red_neuronal=individuo, X=X, Y=Y)\n",
    "        fitness.append(val_fitness)\n",
    "    return np.array(fitness)\n",
    "\n",
    "#--------------------------------------------------------------------\n",
    "def evaluar_poblacion_paralelo(poblacion,  X, Y, n_jobs=-1):\n",
    "    \"\"\"Evalúa la población en paralelo usando multiprocessing.\"\"\"\n",
    "    print(f\"Evaluando población en paralelo ({n_jobs} núcleos)...\")\n",
    "    # Configurar el número de workers (n_jobs=-1 usa todos los núcleos)\n",
    "    n_jobs = cpu_count() if n_jobs == -1 else n_jobs\n",
    "\n",
    "    # Evaluar en paralelo\n",
    "\n",
    "    resultados = Parallel(\n",
    "    n_jobs = n_jobs-1,\n",
    "    timeout = 300,  # 5min\n",
    "    verbose = 10\n",
    "    )(\n",
    "        delayed(funcion_fitness)(red_neuronal=individuo, X=X, Y=Y)\n",
    "        for individuo in poblacion\n",
    "    )\n",
    "\n",
    "    fitness = np.array(resultados)\n",
    "    \n",
    "    return fitness\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "def seleccionar_padres(population, fitness, k=5):\n",
    "    \"\"\"Selección por torneo: el mejor de dos sobrevive.\"\"\"\n",
    "    \"\"\"Selecciona dos padres usando selección por torneo.\"\"\"\n",
    "    torneo = random.sample(list(zip(population, fitness)), k=k)\n",
    "    # print(\"torneo:\", torneo)\n",
    "    torneo.sort(key=lambda x: x[1], reverse=True)  # Ordenar por F1-score\n",
    "    return torneo[0][0], torneo[1][0]  # Retornar los dos mejores individuos\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "def elitismo(poblacion, fitness, tam_elite=2):\n",
    "    \"\"\"Selecciona los 'tam_elite' mejores best_individuos.\"\"\"\n",
    "    # Ordenar por fitness (mayor = mejor)\n",
    "    ranked_indices = np.argsort(fitness)[::-1]\n",
    "    elites = [poblacion[i] for i in ranked_indices[:tam_elite]]\n",
    "    return elites\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "def cruzar_intercambio(padre1, padre2, prob_intercambio=0.7, prob_cruza = 0.9):\n",
    "    \"\"\"Cruce: intercambia pesos de dos padres de acuerdo a la probabilidad de intercambio.\"\"\"\n",
    "    # Si pasa el umbral de probabilidad de cruza se aplica el intercambio\n",
    "    if np.random.rand() <  prob_cruza:\n",
    "        # Crea el modelo de la red neuronal \n",
    "        hijo1 = RedNeuronal(_TAM_ENTRADA, _TAM_SALIDA)\n",
    "        hijo2 = RedNeuronal(_TAM_ENTRADA, _TAM_SALIDA)\n",
    "        with torch.no_grad():\n",
    "            # padre1.parameters() Obtiene los parámetros de la red: weight y bias\n",
    "            for param_h1, param_h2,  param_p1, param_p2 in zip(hijo1.parameters(), hijo2.parameters(),  padre1.parameters(), padre2.parameters()):\n",
    "                mask = torch.rand_like(param_h1) > prob_intercambio\n",
    "                param_h1.copy_(mask * param_p1 + (~mask) * param_p2)\n",
    "                param_h2.copy_(mask * param_p2 + (~mask) * param_p1)\n",
    "\n",
    "    else:\n",
    "        hijo1, hijo2 = padre1, padre2\n",
    "\n",
    "    return hijo1, hijo2\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "def cruzar_aritmetica(padre1, padre2, alpha=0.5, prob_cruza = 0.9):\n",
    "\n",
    "    # Si pasa el umbral de probabilidad de cruza se aplica el intercambio\n",
    "    if np.random.rand() <  prob_cruza:\n",
    "        \"\"\"Cruce: Aplica la cruza aritmética\"\"\"\n",
    "        # Crea el modelo de la red neuronal \n",
    "        hijo1 = RedNeuronal(_TAM_ENTRADA, _TAM_SALIDA)\n",
    "        hijo2 = RedNeuronal(_TAM_ENTRADA, _TAM_SALIDA)\n",
    "        with torch.no_grad():\n",
    "            # padre1.parameters() Obtiene los parámetros de la red: weight y bias\n",
    "            for param_h1, param_h2,  param_p1, param_p2 in zip(hijo1.parameters(), hijo2.parameters(),  padre1.parameters(), padre2.parameters()):\n",
    "                param_h1.copy_((alpha * param_p1) + ((1 - alpha) * param_p2))\n",
    "                param_h2.copy_((alpha * param_p2) + ((1 - alpha) * param_p1))\n",
    "            \n",
    "    else:\n",
    "        hijo1, hijo2 = padre1, padre2\n",
    "    return hijo1, hijo2\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "def mutar(red_neuronal, intensidad_ruido=0.01, TASA_MUTACION = 0.1):\n",
    "    \"\"\"Mutación: añade ruido gaussiano a los pesos con probabilidad TASA_MUTACION e intensidad (intensidad_ruido).\"\"\"\n",
    "    if np.random.rand() < TASA_MUTACION:\n",
    "        with torch.no_grad():\n",
    "            for param in red_neuronal.parameters():\n",
    "                # Devuelve un tensor con el mismo tamaño que la entrada que se rellena con números aleatorios \n",
    "                # de una distribución normal con media 0 y varianza 1.\n",
    "                ruido = torch.randn_like(param) * intensidad_ruido\n",
    "                param.add_(ruido)     \n",
    "    return red_neuronal\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "# --- Algoritmo Evolutivo ---\n",
    "def algoritmo_evolutivo(modelo_red_neuronal, X, Y, tam_poblacion, tam_generaciones, run_paralelo=False):\n",
    "    \"\"\"Ejecuta el algoritmo evolutivo para optimizar la red neuronal.\"\"\"\n",
    "    poblacion = inicializar_poblacion(modelo_red_neuronal, tam_poblacion)\n",
    "    \n",
    "    for generacion in range(tam_generaciones):\n",
    "        if run_paralelo:\n",
    "            fitness = evaluar_poblacion_paralelo(poblacion, X, Y, n_jobs=-1)\n",
    "        else:            \n",
    "            fitness = evaluar_poblacion(poblacion, X, Y)        \n",
    "\n",
    "    \n",
    "        # Reporte de generación\n",
    "        print(f\"Generación {generacion} - Mejor precisión: {max(fitness):.4f}\")\n",
    "        \n",
    "        nueva_poblacion = []\n",
    "        for _ in range(tam_poblacion // 2):\n",
    "            # Selección, cruce y mutación\n",
    "            padre1, padre2 = seleccionar_padres(poblacion,fitness, k=5 )                        \n",
    "            hijo1, hijo2 = cruzar_intercambio(padre1, padre2)\n",
    "            nueva_poblacion.append(mutar(hijo1))\n",
    "            nueva_poblacion.append(mutar(hijo2))\n",
    "\n",
    "        #-----------------\n",
    "        # Población: Los hijos sustituyen a los padres\n",
    "        #-----------------\n",
    "        # poblacion = nueva_poblacion\n",
    "    \n",
    "        #-----------------\n",
    "        # Población con elitismo de padres y parte de los hijos\n",
    "        #-----------------\n",
    "        \n",
    "        K_best_padres = 10\n",
    "        poblacion[:K_best_padres] = elitismo(poblacion, fitness, K_best_padres)\n",
    "        poblacion[K_best_padres:] = nueva_poblacion[K_best_padres: ]\n",
    "\n",
    "\n",
    "    if run_paralelo:\n",
    "        fitness = evaluar_poblacion_paralelo(poblacion, X, Y, n_jobs=-1)\n",
    "    else:            \n",
    "        fitness = evaluar_poblacion(poblacion, X, Y)        \n",
    "\n",
    "    # Evaluar el mejor modelo en train\n",
    "    best_individuo = poblacion[np.argmax(fitness)]\n",
    "    test_f1 = funcion_fitness(best_individuo, X, Y)\n",
    "    print(f\"\\nF1-score final en Train: {test_f1:.3f}\")\n",
    "    return best_individuo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejecución del algoritmo evolutivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generación 0 - Mejor precisión: 0.6814\n",
      "Generación 1 - Mejor precisión: 0.6881\n",
      "Generación 2 - Mejor precisión: 0.6881\n",
      "Generación 3 - Mejor precisión: 0.6918\n",
      "Generación 4 - Mejor precisión: 0.6937\n",
      "Generación 5 - Mejor precisión: 0.6937\n",
      "Generación 6 - Mejor precisión: 0.6949\n",
      "Generación 7 - Mejor precisión: 0.6938\n",
      "Generación 8 - Mejor precisión: 0.6948\n",
      "Generación 9 - Mejor precisión: 0.6970\n",
      "Generación 10 - Mejor precisión: 0.6970\n",
      "Generación 11 - Mejor precisión: 0.6970\n",
      "Generación 12 - Mejor precisión: 0.6970\n",
      "Generación 13 - Mejor precisión: 0.6970\n",
      "Generación 14 - Mejor precisión: 0.6970\n",
      "Generación 15 - Mejor precisión: 0.6970\n",
      "Generación 16 - Mejor precisión: 0.6970\n",
      "Generación 17 - Mejor precisión: 0.6970\n",
      "Generación 18 - Mejor precisión: 0.6970\n",
      "Generación 19 - Mejor precisión: 0.6970\n",
      "Generación 20 - Mejor precisión: 0.6969\n",
      "Generación 21 - Mejor precisión: 0.6969\n",
      "Generación 22 - Mejor precisión: 0.6969\n",
      "Generación 23 - Mejor precisión: 0.6982\n",
      "Generación 24 - Mejor precisión: 0.6982\n",
      "Generación 25 - Mejor precisión: 0.6982\n",
      "Generación 26 - Mejor precisión: 0.6982\n",
      "Generación 27 - Mejor precisión: 0.6982\n",
      "Generación 28 - Mejor precisión: 0.6982\n",
      "Generación 29 - Mejor precisión: 0.6982\n",
      "Generación 30 - Mejor precisión: 0.6982\n",
      "Generación 31 - Mejor precisión: 0.6982\n",
      "Generación 32 - Mejor precisión: 0.6997\n",
      "Generación 33 - Mejor precisión: 0.6997\n",
      "Generación 34 - Mejor precisión: 0.6997\n",
      "Generación 35 - Mejor precisión: 0.6991\n",
      "Generación 36 - Mejor precisión: 0.6991\n",
      "Generación 37 - Mejor precisión: 0.6996\n",
      "Generación 38 - Mejor precisión: 0.6996\n",
      "Generación 39 - Mejor precisión: 0.6996\n",
      "Generación 40 - Mejor precisión: 0.6999\n",
      "Generación 41 - Mejor precisión: 0.7004\n",
      "Generación 42 - Mejor precisión: 0.7004\n",
      "Generación 43 - Mejor precisión: 0.7004\n",
      "Generación 44 - Mejor precisión: 0.7006\n",
      "Generación 45 - Mejor precisión: 0.7006\n",
      "Generación 46 - Mejor precisión: 0.7006\n",
      "Generación 47 - Mejor precisión: 0.7006\n",
      "Generación 48 - Mejor precisión: 0.7006\n",
      "Generación 49 - Mejor precisión: 0.7006\n",
      "\n",
      "F1-score final en Train: 0.701\n"
     ]
    }
   ],
   "source": [
    "best_individuo = algoritmo_evolutivo(modelo_red_neuronal, X_tensor_train, Y_train_encoded, tam_poblacion=50, tam_generaciones=50, run_paralelo=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación del mejor individuo de la evolución (mejor modelo de red neuronal evolucionada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score final en test set: 0.6342\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Evaluación en test set ---\n",
    "best_red_neuronal = best_individuo\n",
    "best_red_neuronal.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = best_red_neuronal(X_tensor_test)\n",
    "    y_pred = torch.argmax(y_pred, axis=1)\n",
    "    score = f1_score(Y_test_encoded, y_pred, average=\"macro\")\n",
    "\n",
    "print(f\"F1-score final en test set: {score:.4f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
